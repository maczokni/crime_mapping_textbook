<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Regression analysis (a refresher) | Crime Mapping in R</title>
  <meta name="description" content="Worksheets for labs of Crime Mapping course" />
  <meta name="generator" content="bookdown 0.39 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Regression analysis (a refresher) | Crime Mapping in R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Worksheets for labs of Crime Mapping course" />
  <meta name="github-repo" content="maczokni/crime_mapping_textbook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Regression analysis (a refresher) | Crime Mapping in R" />
  
  <meta name="twitter:description" content="Worksheets for labs of Crime Mapping course" />
  

<meta name="author" content="Reka Solymosi and Juanjo Medina" />


<meta name="date" content="2025-01-31" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="global-and-local-spatial-autocorrelation.html"/>
<link rel="next" href="spatial-regression-models.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<link href="libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<link href="libs/leaflet-1.3.1/leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-1.3.1/leaflet.js"></script>
<link href="libs/leafletfix-1.0.0/leafletfix.css" rel="stylesheet" />
<script src="libs/proj4-2.6.2/proj4.min.js"></script>
<script src="libs/Proj4Leaflet-1.0.1/proj4leaflet.js"></script>
<link href="libs/rstudio_leaflet-1.3.1/rstudio_leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-binding-2.2.2/leaflet.js"></script>
<script src="libs/leaflet-providers-2.0.0/leaflet-providers_2.0.0.js"></script>
<script src="libs/leaflet-providers-plugin-2.2.2/leaflet-providers-plugin.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Crime Mapping in R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prelude</a>
<ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#introduction"><i class="fa fa-check"></i><b>0.1</b> Introduction</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#disclaimer"><i class="fa fa-check"></i><b>0.2</b> Disclaimer</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html"><i class="fa fa-check"></i><b>1</b> A first lesson about R</a>
<ul>
<li class="chapter" data-level="1.1" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#install-r-r-studio"><i class="fa fa-check"></i><b>1.1</b> Install R &amp; R Studio</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#activity-1-identifying-your-operating-system"><i class="fa fa-check"></i><b>1.1.1</b> Activity 1: Identifying your operating system</a></li>
<li class="chapter" data-level="1.1.2" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#activity-2-install-r-r-studio"><i class="fa fa-check"></i><b>1.1.2</b> Activity 2: Install R &amp; R Studio</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#open-up-and-explore-rstudio"><i class="fa fa-check"></i><b>1.2</b> Open up and explore RStudio</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#activity-3-opening-up-the-script-pane"><i class="fa fa-check"></i><b>1.2.1</b> Activity 3: Opening up the script pane</a></li>
<li class="chapter" data-level="1.2.2" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#the-four-panes-of-r-studio"><i class="fa fa-check"></i><b>1.2.2</b> The four panes of R Studio</a></li>
<li class="chapter" data-level="1.2.3" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#activity-4-interacting-with-the-4-panes"><i class="fa fa-check"></i><b>1.2.3</b> Activity 4: Interacting with the 4 panes</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#customising-the-rstudio-look"><i class="fa fa-check"></i><b>1.3</b> Customising the RStudio look</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#functions"><i class="fa fa-check"></i><b>1.3.1</b> Functions</a></li>
<li class="chapter" data-level="1.3.2" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#objects"><i class="fa fa-check"></i><b>1.3.2</b> Objects</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#packages"><i class="fa fa-check"></i><b>1.4</b> Packages</a></li>
<li class="chapter" data-level="1.5" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#exploring-data"><i class="fa fa-check"></i><b>1.5</b> Exploring data</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#activity-8-playing-around-with-data"><i class="fa fa-check"></i><b>1.5.1</b> Activity 8: Playing around with data</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#getting-organised-r-projects"><i class="fa fa-check"></i><b>1.6</b> Getting organised: R Projects</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="making-maps-in-r.html"><a href="making-maps-in-r.html"><i class="fa fa-check"></i><b>2</b> Making Maps in R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="making-maps-in-r.html"><a href="making-maps-in-r.html#a-quick-introduction-of-terms"><i class="fa fa-check"></i><b>2.1</b> A quick introduction of terms</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="making-maps-in-r.html"><a href="making-maps-in-r.html#geospatial-perspective---the-basics"><i class="fa fa-check"></i><b>2.1.1</b> Geospatial Perspective - The Basics</a></li>
<li class="chapter" data-level="2.1.2" data-path="making-maps-in-r.html"><a href="making-maps-in-r.html#summary"><i class="fa fa-check"></i><b>2.1.2</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="making-maps-in-r.html"><a href="making-maps-in-r.html#getting-some-spatial-data-to-put-on-a-map"><i class="fa fa-check"></i><b>2.2</b> Getting some spatial data to put on a map</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="making-maps-in-r.html"><a href="making-maps-in-r.html#find-some-relevant-data-to-show-obtaining-data-on-crime"><i class="fa fa-check"></i><b>2.2.1</b> Find some relevant data to show: obtaining data on crime</a></li>
<li class="chapter" data-level="2.2.2" data-path="making-maps-in-r.html"><a href="making-maps-in-r.html#activity-1-get-some-crime-data"><i class="fa fa-check"></i><b>2.2.2</b> Activity 1: Get some crime data</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="making-maps-in-r.html"><a href="making-maps-in-r.html#from-dataframes-to-spatial-objects-finding-spatial-information-in-our-data"><i class="fa fa-check"></i><b>2.3</b> From dataframes to spatial objects: finding spatial information in our data</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="making-maps-in-r.html"><a href="making-maps-in-r.html#activity-2-find-the-spatial-data"><i class="fa fa-check"></i><b>2.3.1</b> Activity 2: Find the spatial data</a></li>
<li class="chapter" data-level="2.3.2" data-path="making-maps-in-r.html"><a href="making-maps-in-r.html#the-point"><i class="fa fa-check"></i><b>2.3.2</b> The point</a></li>
<li class="chapter" data-level="2.3.3" data-path="making-maps-in-r.html"><a href="making-maps-in-r.html#the-line"><i class="fa fa-check"></i><b>2.3.3</b> The line</a></li>
<li class="chapter" data-level="2.3.4" data-path="making-maps-in-r.html"><a href="making-maps-in-r.html#the-polygon"><i class="fa fa-check"></i><b>2.3.4</b> The polygon</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="making-maps-in-r.html"><a href="making-maps-in-r.html#putting-crime-on-the-map---simple-features"><i class="fa fa-check"></i><b>2.4</b> Putting crime on the map - simple features</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="making-maps-in-r.html"><a href="making-maps-in-r.html#mapping-points-with-sf"><i class="fa fa-check"></i><b>2.4.1</b> Mapping points with sf</a></li>
<li class="chapter" data-level="2.4.2" data-path="making-maps-in-r.html"><a href="making-maps-in-r.html#mapping-data-by-joining-it-to-sf-objects"><i class="fa fa-check"></i><b>2.4.2</b> Mapping data by joining it to sf objects</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="making-maps-in-r.html"><a href="making-maps-in-r.html#summary-1"><i class="fa fa-check"></i><b>2.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="thematic-maps-in-r.html"><a href="thematic-maps-in-r.html"><i class="fa fa-check"></i><b>3</b> Thematic maps in R</a>
<ul>
<li class="chapter" data-level="3.1" data-path="thematic-maps-in-r.html"><a href="thematic-maps-in-r.html#introduction-1"><i class="fa fa-check"></i><b>3.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="thematic-maps-in-r.html"><a href="thematic-maps-in-r.html#activity-1-spot-the-difference"><i class="fa fa-check"></i><b>3.1.1</b> Activity 1: Spot the difference</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="thematic-maps-in-r.html"><a href="thematic-maps-in-r.html#creating-thematic-maps"><i class="fa fa-check"></i><b>3.2</b> Creating thematic maps</a></li>
<li class="chapter" data-level="3.3" data-path="thematic-maps-in-r.html"><a href="thematic-maps-in-r.html#classification-systems-for-thematic-maps"><i class="fa fa-check"></i><b>3.3</b> Classification systems for thematic maps</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="thematic-maps-in-r.html"><a href="thematic-maps-in-r.html#activity-2-comparing-classifications"><i class="fa fa-check"></i><b>3.3.1</b> Activity 2: Comparing classifications</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="thematic-maps-in-r.html"><a href="thematic-maps-in-r.html#using-graduated-symbols"><i class="fa fa-check"></i><b>3.4</b> Using graduated symbols</a></li>
<li class="chapter" data-level="3.5" data-path="thematic-maps-in-r.html"><a href="thematic-maps-in-r.html#mapping-rates-rather-than-counts"><i class="fa fa-check"></i><b>3.5</b> Mapping rates rather than counts</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="thematic-maps-in-r.html"><a href="thematic-maps-in-r.html#activity-3-getting-population-data-from-the-census"><i class="fa fa-check"></i><b>3.5.1</b> Activity 3: Getting population data from the census</a></li>
<li class="chapter" data-level="3.5.2" data-path="thematic-maps-in-r.html"><a href="thematic-maps-in-r.html#activity-5-mapping-crime-rates"><i class="fa fa-check"></i><b>3.5.2</b> Activity 5: Mapping crime rates</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="thematic-maps-in-r.html"><a href="thematic-maps-in-r.html#summary-2"><i class="fa fa-check"></i><b>3.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="performing-spatial-operations-in-r.html"><a href="performing-spatial-operations-in-r.html"><i class="fa fa-check"></i><b>4</b> Performing spatial operations in R</a>
<ul>
<li class="chapter" data-level="4.1" data-path="performing-spatial-operations-in-r.html"><a href="performing-spatial-operations-in-r.html#criminality-of-place"><i class="fa fa-check"></i><b>4.1</b> Criminality of place</a></li>
<li class="chapter" data-level="4.2" data-path="performing-spatial-operations-in-r.html"><a href="performing-spatial-operations-in-r.html#getting-data-of-this-week"><i class="fa fa-check"></i><b>4.2</b> Getting data of this week</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="performing-spatial-operations-in-r.html"><a href="performing-spatial-operations-in-r.html#activity-1-subsetting-using-pattern-matching"><i class="fa fa-check"></i><b>4.2.1</b> Activity 1: Subsetting using pattern matching</a></li>
<li class="chapter" data-level="4.2.2" data-path="performing-spatial-operations-in-r.html"><a href="performing-spatial-operations-in-r.html#activity-2-pattern-matching-to-find-city-centre-premises"><i class="fa fa-check"></i><b>4.2.2</b> Activity 2: Pattern matching to find city centre premises</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="performing-spatial-operations-in-r.html"><a href="performing-spatial-operations-in-r.html#geocoding-from-an-address"><i class="fa fa-check"></i><b>4.3</b> Geocoding from an address</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="performing-spatial-operations-in-r.html"><a href="performing-spatial-operations-in-r.html#activity-3-getting-address-from-post-code-using-an-api"><i class="fa fa-check"></i><b>4.3.1</b> Activity 3: Getting address from post code using an API</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="performing-spatial-operations-in-r.html"><a href="performing-spatial-operations-in-r.html#making-interactive-maps-with-leaflet"><i class="fa fa-check"></i><b>4.4</b> Making interactive maps with leaflet</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="performing-spatial-operations-in-r.html"><a href="performing-spatial-operations-in-r.html#activity-4-making-an-interactive-map"><i class="fa fa-check"></i><b>4.4.1</b> Activity 4: Making an interactive map</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="performing-spatial-operations-in-r.html"><a href="performing-spatial-operations-in-r.html#spatial-operations"><i class="fa fa-check"></i><b>4.5</b> Spatial operations</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="performing-spatial-operations-in-r.html"><a href="performing-spatial-operations-in-r.html#coordinate-reference-systems-revisited"><i class="fa fa-check"></i><b>4.5.1</b> Coordinate reference systems revisited</a></li>
<li class="chapter" data-level="4.5.2" data-path="performing-spatial-operations-in-r.html"><a href="performing-spatial-operations-in-r.html#meet-a-new-format-of-shapefile-geojson"><i class="fa fa-check"></i><b>4.5.2</b> Meet a new format of shapefile: geojson</a></li>
<li class="chapter" data-level="4.5.3" data-path="performing-spatial-operations-in-r.html"><a href="performing-spatial-operations-in-r.html#activity-5-subset-points-to-those-within-a-polygon"><i class="fa fa-check"></i><b>4.5.3</b> Activity 5: Subset points to those within a polygon</a></li>
<li class="chapter" data-level="4.5.4" data-path="performing-spatial-operations-in-r.html"><a href="performing-spatial-operations-in-r.html#activity-6-building-buffers"><i class="fa fa-check"></i><b>4.5.4</b> Activity 6: Building buffers</a></li>
<li class="chapter" data-level="4.5.5" data-path="performing-spatial-operations-in-r.html"><a href="performing-spatial-operations-in-r.html#activity-7-counting-points-in-polygon"><i class="fa fa-check"></i><b>4.5.5</b> Activity 7: Counting Points in Polygon</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="more-on-thematic-maps.html"><a href="more-on-thematic-maps.html"><i class="fa fa-check"></i><b>5</b> More on thematic maps</a>
<ul>
<li class="chapter" data-level="5.1" data-path="more-on-thematic-maps.html"><a href="more-on-thematic-maps.html#pro-tip-do-i-need-to-install-this-package"><i class="fa fa-check"></i><b>5.1</b> Pro-tip: do I need to install this package?</a></li>
<li class="chapter" data-level="5.2" data-path="more-on-thematic-maps.html"><a href="more-on-thematic-maps.html#smoothing-rates-adjusting-for-small-sample-noise"><i class="fa fa-check"></i><b>5.2</b> Smoothing rates: adjusting for small sample noise</a></li>
<li class="chapter" data-level="5.3" data-path="more-on-thematic-maps.html"><a href="more-on-thematic-maps.html#binning-points"><i class="fa fa-check"></i><b>5.3</b> Binning points</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="more-on-thematic-maps.html"><a href="more-on-thematic-maps.html#the-binning-process"><i class="fa fa-check"></i><b>5.3.1</b> The Binning Process</a></li>
<li class="chapter" data-level="5.3.2" data-path="more-on-thematic-maps.html"><a href="more-on-thematic-maps.html#different-binning-techniques"><i class="fa fa-check"></i><b>5.3.2</b> Different Binning Techniques</a></li>
<li class="chapter" data-level="5.3.3" data-path="more-on-thematic-maps.html"><a href="more-on-thematic-maps.html#activity-7-hexbinning"><i class="fa fa-check"></i><b>5.3.3</b> Activity 7: Hexbinning</a></li>
<li class="chapter" data-level="5.3.4" data-path="more-on-thematic-maps.html"><a href="more-on-thematic-maps.html#activity-8-rectangular-binning"><i class="fa fa-check"></i><b>5.3.4</b> Activity 8: Rectangular binning</a></li>
<li class="chapter" data-level="5.3.5" data-path="more-on-thematic-maps.html"><a href="more-on-thematic-maps.html#multivariate-binning"><i class="fa fa-check"></i><b>5.3.5</b> Multivariate binning</a></li>
<li class="chapter" data-level="5.3.6" data-path="more-on-thematic-maps.html"><a href="more-on-thematic-maps.html#benefits-of-binning"><i class="fa fa-check"></i><b>5.3.6</b> Benefits of Binning</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="more-on-thematic-maps.html"><a href="more-on-thematic-maps.html#a-note-of-caution-maup"><i class="fa fa-check"></i><b>5.4</b> A note of caution: MAUP</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="more-on-thematic-maps.html"><a href="more-on-thematic-maps.html#what-is-maup"><i class="fa fa-check"></i><b>5.4.1</b> What is MAUP?</a></li>
<li class="chapter" data-level="5.4.2" data-path="more-on-thematic-maps.html"><a href="more-on-thematic-maps.html#why-does-maup-matter"><i class="fa fa-check"></i><b>5.4.2</b> Why does MAUP matter?</a></li>
<li class="chapter" data-level="5.4.3" data-path="more-on-thematic-maps.html"><a href="more-on-thematic-maps.html#what-can-we-do"><i class="fa fa-check"></i><b>5.4.3</b> What can we do?</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="more-on-thematic-maps.html"><a href="more-on-thematic-maps.html#transforming-polygons"><i class="fa fa-check"></i><b>5.5</b> Transforming polygons</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="more-on-thematic-maps.html"><a href="more-on-thematic-maps.html#activity-9-cartograms"><i class="fa fa-check"></i><b>5.5.1</b> Activity 9: Cartograms</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="more-on-thematic-maps.html"><a href="more-on-thematic-maps.html#references-and-further-reading"><i class="fa fa-check"></i><b>5.6</b> References and further reading</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="more-on-thematic-maps.html"><a href="more-on-thematic-maps.html#binning"><i class="fa fa-check"></i><b>5.6.1</b> Binning</a></li>
<li class="chapter" data-level="5.6.2" data-path="more-on-thematic-maps.html"><a href="more-on-thematic-maps.html#maup"><i class="fa fa-check"></i><b>5.6.2</b> MAUP</a></li>
<li class="chapter" data-level="5.6.3" data-path="more-on-thematic-maps.html"><a href="more-on-thematic-maps.html#transforming-polygons-1"><i class="fa fa-check"></i><b>5.6.3</b> Transforming polygons</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="studying-spatial-point-patterns.html"><a href="studying-spatial-point-patterns.html"><i class="fa fa-check"></i><b>6</b> Studying spatial point patterns</a>
<ul>
<li class="chapter" data-level="6.1" data-path="studying-spatial-point-patterns.html"><a href="studying-spatial-point-patterns.html#what-well-do-today"><i class="fa fa-check"></i><b>6.1</b> What we’ll do today</a></li>
<li class="chapter" data-level="6.2" data-path="studying-spatial-point-patterns.html"><a href="studying-spatial-point-patterns.html#getting-the-data"><i class="fa fa-check"></i><b>6.2</b> Getting the data</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="studying-spatial-point-patterns.html"><a href="studying-spatial-point-patterns.html#activity-1-getting-the-data-into-spatstat-the-problem-with-duplicates"><i class="fa fa-check"></i><b>6.2.1</b> Activity 1: Getting the data into spatstat: the problem with duplicates</a></li>
<li class="chapter" data-level="6.2.2" data-path="studying-spatial-point-patterns.html"><a href="studying-spatial-point-patterns.html#activity-2-inspecting-our-data-with-spatstat"><i class="fa fa-check"></i><b>6.2.2</b> Activity 2: Inspecting our data with spatstat</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="studying-spatial-point-patterns.html"><a href="studying-spatial-point-patterns.html#density-estimates"><i class="fa fa-check"></i><b>6.3</b> Density estimates</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="studying-spatial-point-patterns.html"><a href="studying-spatial-point-patterns.html#activity-3-density-maps"><i class="fa fa-check"></i><b>6.3.1</b> Activity 3: Density maps</a></li>
<li class="chapter" data-level="6.3.2" data-path="studying-spatial-point-patterns.html"><a href="studying-spatial-point-patterns.html#activity-4-adding-some-context"><i class="fa fa-check"></i><b>6.3.2</b> Activity 4: Adding some context</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="studying-spatial-point-patterns.html"><a href="studying-spatial-point-patterns.html#spatial-point-patterns-along-networks"><i class="fa fa-check"></i><b>6.4</b> Spatial point patterns along networks</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="studying-spatial-point-patterns.html"><a href="studying-spatial-point-patterns.html#activity-5-spatial-point-pattern-processes-along-networks"><i class="fa fa-check"></i><b>6.4.1</b> Activity 5: Spatial point pattern processes along networks</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="studying-spatial-point-patterns.html"><a href="studying-spatial-point-patterns.html#recap"><i class="fa fa-check"></i><b>6.5</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="global-and-local-spatial-autocorrelation.html"><a href="global-and-local-spatial-autocorrelation.html"><i class="fa fa-check"></i><b>7</b> Global and local spatial autocorrelation</a>
<ul>
<li class="chapter" data-level="7.1" data-path="global-and-local-spatial-autocorrelation.html"><a href="global-and-local-spatial-autocorrelation.html#get-data"><i class="fa fa-check"></i><b>7.1</b> Get data</a></li>
<li class="chapter" data-level="7.2" data-path="global-and-local-spatial-autocorrelation.html"><a href="global-and-local-spatial-autocorrelation.html#what-is-a-neighbour"><i class="fa fa-check"></i><b>7.2</b> What is a neighbour?</a></li>
<li class="chapter" data-level="7.3" data-path="global-and-local-spatial-autocorrelation.html"><a href="global-and-local-spatial-autocorrelation.html#putting-neighbourness-in-our-analysis---constructing-a-spatial-weight-matrix"><i class="fa fa-check"></i><b>7.3</b> Putting ‘neighbourness’ in our analysis - constructing a spatial weight matrix</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="global-and-local-spatial-autocorrelation.html"><a href="global-and-local-spatial-autocorrelation.html#activity-1-burglaries-in-manchester-city-centre-ward"><i class="fa fa-check"></i><b>7.3.1</b> Activity 1: Burglaries in Manchester City Centre ward</a></li>
<li class="chapter" data-level="7.3.2" data-path="global-and-local-spatial-autocorrelation.html"><a href="global-and-local-spatial-autocorrelation.html#activity-2-manually-explore-neighbours"><i class="fa fa-check"></i><b>7.3.2</b> Activity 2: Manually explore neighbours</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="global-and-local-spatial-autocorrelation.html"><a href="global-and-local-spatial-autocorrelation.html#creating-a-list-of-neighbours"><i class="fa fa-check"></i><b>7.4</b> Creating a list of neighbours</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="global-and-local-spatial-autocorrelation.html"><a href="global-and-local-spatial-autocorrelation.html#activity-3-creating-a-neighbour-list"><i class="fa fa-check"></i><b>7.4.1</b> Activity 3: Creating a neighbour list</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="global-and-local-spatial-autocorrelation.html"><a href="global-and-local-spatial-autocorrelation.html#generating-the-weight-matrix"><i class="fa fa-check"></i><b>7.5</b> Generating the weight matrix</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="global-and-local-spatial-autocorrelation.html"><a href="global-and-local-spatial-autocorrelation.html#activity-4-building-a-spatial-weights-matrix"><i class="fa fa-check"></i><b>7.5.1</b> Activity 4: Building a spatial weights matrix</a></li>
<li class="chapter" data-level="7.5.2" data-path="global-and-local-spatial-autocorrelation.html"><a href="global-and-local-spatial-autocorrelation.html#activity-5-row-standardised-spatial-weights-matrix"><i class="fa fa-check"></i><b>7.5.2</b> Activity 5: Row standardised spatial weights matrix</a></li>
<li class="chapter" data-level="7.5.3" data-path="global-and-local-spatial-autocorrelation.html"><a href="global-and-local-spatial-autocorrelation.html#activity-6-spatial-weights-list"><i class="fa fa-check"></i><b>7.5.3</b> Activity 6: Spatial weights list</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="global-and-local-spatial-autocorrelation.html"><a href="global-and-local-spatial-autocorrelation.html#morans-i"><i class="fa fa-check"></i><b>7.6</b> Moran’s I</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="global-and-local-spatial-autocorrelation.html"><a href="global-and-local-spatial-autocorrelation.html#activity-7-calculate-morans-i"><i class="fa fa-check"></i><b>7.6.1</b> Activity 7: Calculate Moran’s I</a></li>
<li class="chapter" data-level="7.6.2" data-path="global-and-local-spatial-autocorrelation.html"><a href="global-and-local-spatial-autocorrelation.html#activity-8-moran-scatter-plot"><i class="fa fa-check"></i><b>7.6.2</b> Activity 8: Moran scatter plot</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="global-and-local-spatial-autocorrelation.html"><a href="global-and-local-spatial-autocorrelation.html#local-spatial-autocorrelation"><i class="fa fa-check"></i><b>7.7</b> Local spatial autocorrelation</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="global-and-local-spatial-autocorrelation.html"><a href="global-and-local-spatial-autocorrelation.html#activity-9-get-data-and-weights-for-all-manchester"><i class="fa fa-check"></i><b>7.7.1</b> Activity 9: Get data and weights for all Manchester</a></li>
<li class="chapter" data-level="7.7.2" data-path="global-and-local-spatial-autocorrelation.html"><a href="global-and-local-spatial-autocorrelation.html#activity-10-exploring-a-local-indicator-of-spatial-association-local-morans-i."><i class="fa fa-check"></i><b>7.7.2</b> Activity 10: Exploring a Local Indicator of Spatial Association: Local Moran’s I.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="regression-analysis-a-refresher.html"><a href="regression-analysis-a-refresher.html"><i class="fa fa-check"></i><b>8</b> Regression analysis (a refresher)</a>
<ul>
<li class="chapter" data-level="8.1" data-path="regression-analysis-a-refresher.html"><a href="regression-analysis-a-refresher.html#introduction-2"><i class="fa fa-check"></i><b>8.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="regression-analysis-a-refresher.html"><a href="regression-analysis-a-refresher.html#activity-1-getting-some-homicide-data"><i class="fa fa-check"></i><b>8.1.1</b> Activity 1: Getting some homicide data</a></li>
<li class="chapter" data-level="8.1.2" data-path="regression-analysis-a-refresher.html"><a href="regression-analysis-a-refresher.html#activity-2-familiarise-yourself-with-the-data"><i class="fa fa-check"></i><b>8.1.2</b> Activity 2: Familiarise yourself with the data</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="regression-analysis-a-refresher.html"><a href="regression-analysis-a-refresher.html#motivating-regression"><i class="fa fa-check"></i><b>8.2</b> Motivating regression</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="regression-analysis-a-refresher.html"><a href="regression-analysis-a-refresher.html#activity-3-guessing-games"><i class="fa fa-check"></i><b>8.2.1</b> Activity 3: Guessing games</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="regression-analysis-a-refresher.html"><a href="regression-analysis-a-refresher.html#fitting-a-simple-regression-model"><i class="fa fa-check"></i><b>8.3</b> Fitting a simple regression model</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="regression-analysis-a-refresher.html"><a href="regression-analysis-a-refresher.html#activity-4-regressing-homicide-rate-on-deprivation-score"><i class="fa fa-check"></i><b>8.3.1</b> Activity 4: Regressing homicide rate on deprivation score</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="regression-analysis-a-refresher.html"><a href="regression-analysis-a-refresher.html#residuals-revisited-r-squared"><i class="fa fa-check"></i><b>8.4</b> Residuals revisited: R squared</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="regression-analysis-a-refresher.html"><a href="regression-analysis-a-refresher.html#activity-5-residuals-for-our-homicide-rate-model"><i class="fa fa-check"></i><b>8.4.1</b> Activity 5: Residuals for our homicide rate model</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="regression-analysis-a-refresher.html"><a href="regression-analysis-a-refresher.html#inference-with-regression"><i class="fa fa-check"></i><b>8.5</b> Inference with regression</a></li>
<li class="chapter" data-level="8.6" data-path="regression-analysis-a-refresher.html"><a href="regression-analysis-a-refresher.html#fitting-regression-with-categorical-predictors"><i class="fa fa-check"></i><b>8.6</b> Fitting regression with categorical predictors</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="regression-analysis-a-refresher.html"><a href="regression-analysis-a-refresher.html#activity-6-homicide-rates-in-the-south-v-the-north"><i class="fa fa-check"></i><b>8.6.1</b> Activity 6: Homicide rates in the South v the North</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="regression-analysis-a-refresher.html"><a href="regression-analysis-a-refresher.html#motivating-multiple-regression"><i class="fa fa-check"></i><b>8.7</b> Motivating multiple regression</a></li>
<li class="chapter" data-level="8.8" data-path="regression-analysis-a-refresher.html"><a href="regression-analysis-a-refresher.html#fitting-and-interpreting-a-multiple-regression-model"><i class="fa fa-check"></i><b>8.8</b> Fitting and interpreting a multiple regression model</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="regression-analysis-a-refresher.html"><a href="regression-analysis-a-refresher.html#activity-7-better-explaining-homicide-rates"><i class="fa fa-check"></i><b>8.8.1</b> Activity 7: Better explaining homicide rates</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="regression-analysis-a-refresher.html"><a href="regression-analysis-a-refresher.html#presenting-your-regression-results."><i class="fa fa-check"></i><b>8.9</b> Presenting your regression results.</a>
<ul>
<li class="chapter" data-level="8.9.1" data-path="regression-analysis-a-refresher.html"><a href="regression-analysis-a-refresher.html#activity-8-plotting-your-results"><i class="fa fa-check"></i><b>8.9.1</b> Activity 8: Plotting your results</a></li>
</ul></li>
<li class="chapter" data-level="8.10" data-path="regression-analysis-a-refresher.html"><a href="regression-analysis-a-refresher.html#rescaling-input-variables-to-assist-interpretation"><i class="fa fa-check"></i><b>8.10</b> Rescaling input variables to assist interpretation</a></li>
<li class="chapter" data-level="8.11" data-path="regression-analysis-a-refresher.html"><a href="regression-analysis-a-refresher.html#testing-conditional-hypothesis-interactions"><i class="fa fa-check"></i><b>8.11</b> Testing conditional hypothesis: interactions</a>
<ul>
<li class="chapter" data-level="8.11.1" data-path="regression-analysis-a-refresher.html"><a href="regression-analysis-a-refresher.html#activity-9-interaction-effects"><i class="fa fa-check"></i><b>8.11.1</b> Activity 9: Interaction effects</a></li>
</ul></li>
<li class="chapter" data-level="8.12" data-path="regression-analysis-a-refresher.html"><a href="regression-analysis-a-refresher.html#model-building-and-variable-selection"><i class="fa fa-check"></i><b>8.12</b> Model building and variable selection</a></li>
<li class="chapter" data-level="8.13" data-path="regression-analysis-a-refresher.html"><a href="regression-analysis-a-refresher.html#regression-assumptions"><i class="fa fa-check"></i><b>8.13</b> Regression assumptions</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="spatial-regression-models.html"><a href="spatial-regression-models.html"><i class="fa fa-check"></i><b>9</b> Spatial regression models</a>
<ul>
<li class="chapter" data-level="9.1" data-path="spatial-regression-models.html"><a href="spatial-regression-models.html#introduction-3"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="spatial-regression-models.html"><a href="spatial-regression-models.html#looking-at-the-residuals-and-testing-for-spatial-autocorrelation-in-regression"><i class="fa fa-check"></i><b>9.2</b> Looking at the residuals and testing for spatial autocorrelation in regression</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="spatial-regression-models.html"><a href="spatial-regression-models.html#activity-1-a-non-spatial-regression-on-spatial-data---listen-to-the-residuals"><i class="fa fa-check"></i><b>9.2.1</b> Activity 1: A non-spatial regression on spatial data - listen to the residuals</a></li>
<li class="chapter" data-level="9.2.2" data-path="spatial-regression-models.html"><a href="spatial-regression-models.html#activity-2-spatial-autocorrelation-again"><i class="fa fa-check"></i><b>9.2.2</b> Activity 2: Spatial autocorrelation (again)</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="spatial-regression-models.html"><a href="spatial-regression-models.html#what-to-do-now"><i class="fa fa-check"></i><b>9.3</b> What to do now?</a></li>
<li class="chapter" data-level="9.4" data-path="spatial-regression-models.html"><a href="spatial-regression-models.html#spatial-regimes"><i class="fa fa-check"></i><b>9.4</b> Spatial Regimes</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="spatial-regression-models.html"><a href="spatial-regression-models.html#activity-3-assessing-spatial-regimes-using-residuals"><i class="fa fa-check"></i><b>9.4.1</b> Activity 3: Assessing spatial regimes using residuals</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="spatial-regression-models.html"><a href="spatial-regression-models.html#lagrange-multipliers"><i class="fa fa-check"></i><b>9.5</b> Lagrange multipliers</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="spatial-regression-models.html"><a href="spatial-regression-models.html#activity-4-lagrange-multiplier-tests"><i class="fa fa-check"></i><b>9.5.1</b> Activity 4: Lagrange multiplier tests</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="spatial-regression-models.html"><a href="spatial-regression-models.html#fitting-and-interpreting-a-spatially-lagged-model"><i class="fa fa-check"></i><b>9.6</b> Fitting and interpreting a spatially lagged model</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="spatial-regression-models.html"><a href="spatial-regression-models.html#activity-5-spatial-lag-model"><i class="fa fa-check"></i><b>9.6.1</b> Activity 5: Spatial lag model</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="spatial-regression-models.html"><a href="spatial-regression-models.html#fitting-an-interpreting-a-spatial-error-model"><i class="fa fa-check"></i><b>9.7</b> Fitting an interpreting a spatial error model</a>
<ul>
<li class="chapter" data-level="9.7.1" data-path="spatial-regression-models.html"><a href="spatial-regression-models.html#activity-6-spatial-error-model"><i class="fa fa-check"></i><b>9.7.1</b> Activity 6: Spatial error model</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="spatial-regression-models.html"><a href="spatial-regression-models.html#time-matters"><i class="fa fa-check"></i><b>9.8</b> Time matters!</a>
<ul>
<li class="chapter" data-level="9.8.1" data-path="spatial-regression-models.html"><a href="spatial-regression-models.html#activity-7-small-multiples"><i class="fa fa-check"></i><b>9.8.1</b> Activity 7: Small multiples</a></li>
<li class="chapter" data-level="9.8.2" data-path="spatial-regression-models.html"><a href="spatial-regression-models.html#activity-8-animations"><i class="fa fa-check"></i><b>9.8.2</b> Activity 8: Animations</a></li>
</ul></li>
<li class="chapter" data-level="9.9" data-path="spatial-regression-models.html"><a href="spatial-regression-models.html#recap-1"><i class="fa fa-check"></i><b>9.9</b> Recap</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Crime Mapping in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regression-analysis-a-refresher" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">Chapter 8</span> Regression analysis (a refresher)<a href="regression-analysis-a-refresher.html#regression-analysis-a-refresher" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="introduction-2" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> Introduction<a href="regression-analysis-a-refresher.html#introduction-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In science one of our main concerns is to develop models of the world, models that help us to understand the world a bit better or to predict how things will develop better. You can read more about modelling in scientific research <a href="https://www.visionlearning.com/en/library/Process-of-Science/49/Modeling-in-Scientific-Research/153">here</a>. Statistics provides a set of tools that help researchers build and test scientific models.</p>
<p>Our models can be simple. We can think that unemployment is a factor that may help us to understand why cities differ in their level of violent crime. We could express such a model like this:</p>
<p><img src="img/model1.png" /></p>
<p>Surely we know the world is complex and likely there are other things that may help us to understand why some cities have more crime than others. So, we may want to have tools that allow us to examine such models. Like, for example, the one below:</p>
<p><img src="img/model2.png" /></p>
<p>In this session we are going to cover regression analysis or, rather, we are beginning to talk about regression modelling. Some experience with data analysis modules is a pre-requisite for this module, so it is likely you have learned this in those courses, but just for the sake of those who may be a bit rusty, we will have this refresher here.</p>
<p>We’ll be making use of the following packages:</p>
<ul>
<li><code>readr</code><br />
</li>
<li><code>ggplot2</code><br />
</li>
<li><code>arm</code><br />
</li>
<li><code>sjPlot</code><br />
</li>
<li><code>effects</code><br />
</li>
<li><code>lmtest</code><br />
</li>
<li><code>car</code><br />
</li>
<li><code>olsrr</code></li>
</ul>
<p>Regression has been one the main technique of data analysis in the social sciences for many years and it belongs to a family of techniques called generalised linear models. Regression is a flexible model that allows you to “explain” or “predict” a given outcome (Y), variously called your outcome, response or dependent variable, as a function of a number of what is variously called inputs, features or independent, explanatory, or predictive variables (X1, X2, X3, etc.). Following Gelman and Hill (2007), we will try to stick for the most part to the terms outputs and inputs.</p>
<p>Today we will cover linear regression or ordinary least squares regression (OLS), which is a technique that you use when you are interested in explaining variation in an interval level variable. First we will see how you can use regression analysis when you only have one input and then we will move to situations when we have several explanatory variables or inputs. For those of you already familiar with regression analysis this session can be a bit of a refresher, for those that aren’t a bit of an introduction. Today we will cover regression models more generally and in the next lab we will discuss adaptations to the regression model that are necessary when you have spatial autocorrelation.</p>
<div id="activity-1-getting-some-homicide-data" class="section level3 hasAnchor" number="8.1.1">
<h3><span class="header-section-number">8.1.1</span> Activity 1: Getting some homicide data<a href="regression-analysis-a-refresher.html#activity-1-getting-some-homicide-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We will use a dataset that includes information about homicides in the US, as well as information in a number of sociodemographic variables that are often thought of as associated with the geographical distribution of homicides. As always, you can download the data from the webpage or it is available on blackboard under the data tab for this week’s learning materials. Is is the file <code>NAT.csv</code> inside the <code>ncovr.zip</code> file (remember you’ll have to extract the zip folder first!).</p>
<div class="sourceCode" id="cb380"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb380-1"><a href="regression-analysis-a-refresher.html#cb380-1" tabindex="-1"></a>ncovr <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;https://www.dropbox.com/s/zhn66q5y46dontn/NAT.csv?dl=1&quot;</span>)</span></code></pre></div>
<pre><code>## Rows: 3085 Columns: 69
## ── Column specification ─────────────────────────────────────────────
## Delimiter: &quot;,&quot;
## chr  (5): NAME, STATE_NAME, STATE_FIPS, CNTY_FIPS, FIPS
## dbl (64): STFIPS, COFIPS, FIPSNO, SOUTH, HR60, HR70, HR80, HR90, HC60, HC70,...
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<div class="sourceCode" id="cb382"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb382-1"><a href="regression-analysis-a-refresher.html#cb382-1" tabindex="-1"></a><span class="co">#or, use your local path</span></span>
<span id="cb382-2"><a href="regression-analysis-a-refresher.html#cb382-2" tabindex="-1"></a>ncovr <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&#39;data/ncovr/NAT.csv&#39;</span>)</span></code></pre></div>
<pre><code>## Rows: 3085 Columns: 69
## ── Column specification ─────────────────────────────────────────────
## Delimiter: &quot;,&quot;
## chr  (5): NAME, STATE_NAME, STATE_FIPS, CNTY_FIPS, FIPS
## dbl (64): STFIPS, COFIPS, FIPSNO, SOUTH, HR60, HR70, HR80, HR90, HC60, HC70,...
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<p>The dataset contains information about 3085 counties in the US and if you view it you will see it has information about several decades, the 60s, 70s, 80s, and 90s. The number at the end of the variable names denotes the relevant decade and you will see that for each decade we have the same variables.</p>
<p>The purpose of this and next session is to help you choose a model to represent the relationship between homicide and various predictors. You can think of a model as a map. A map aims to represent a given reality, but as you may have already discovered there are many ways of presenting the same information through a map. As an analyst you decide what the most appropriate representation for your needs is. Each representation you choose will involve an element of distortion. Maps (and models) are not exact representations of the real word, they are simply good approximations that may serve well a particular functional need. They may not be terribly good reflections of the world, but may give us approximations that allows us to develop useful insights.</p>
<p>Choosing a good model is like choosing a good way for displaying quantitative information in a map. Decisions, decisions, decisions. There are many parameters and options one can choose from. This can be overwhelming, particularly as you are learning how to model and map phenomena. How to make good decisions is something that you learn on earnest by practice, practice, practice. Nobody expects you to get the maps you are doing as you are learning, and the models you are developing as you are learning spot on. So please do not stress out about this. All we can do here is to learn some basic principles and start getting some practice, which you will be able to further develop in a professional context or in further training.</p>
</div>
<div id="activity-2-familiarise-yourself-with-the-data" class="section level3 hasAnchor" number="8.1.2">
<h3><span class="header-section-number">8.1.2</span> Activity 2: Familiarise yourself with the data<a href="regression-analysis-a-refresher.html#activity-2-familiarise-yourself-with-the-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The first step in any analysis is to develop some familiarity with the data you are going to be working with. We have been here before. Read the <a href="https://www.dropbox.com/s/7vdhxjm8bq0p3nu/codebook.pdf?dl=1">codebook</a>. Run summary statistics for your quantitative variables, frequency distributions for your categorical variables, and visualise your variables. This will help you to detect any anomalies and give you a sense for what you have. If, for example, you run a histogram for the homicide rate for 1990 (HR90), you will get a sense of the distribution form –which of course is skewed.</p>
<div class="sourceCode" id="cb384"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb384-1"><a href="regression-analysis-a-refresher.html#cb384-1" tabindex="-1"></a><span class="fu">ggplot</span>(ncovr, <span class="fu">aes</span>(<span class="at">x =</span> HR90)) <span class="sc">+</span> </span>
<span id="cb384-2"><a href="regression-analysis-a-refresher.html#cb384-2" tabindex="-1"></a>  <span class="fu">geom_histogram</span>()</span></code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="crime_mapping_textbook_files/figure-html/unnamed-chunk-232-1.png" width="672" /></p>
<p>We can also look at other variables in our data set. You may wish to use the <code>skim()</code> function from the <code>skimr</code> package maybe, which we introduced all the way back in the first lab!. Once one has gone through the process of exploring the data in this way for all the variables you want to work with, you can start exploring bivariate associations with your dependent variable (also called response or outcome variable). In this case, our outcome variable is homicide rate in the 90s, which we explored in the histogram above (<code>HR90</code>). As an illustration, you could explore the association with resource deprivation (<em>RD90</em>), a measure of the level of concentrated disadvantage or social exclusion in an area, via a scatterplot:</p>
<div class="sourceCode" id="cb386"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb386-1"><a href="regression-analysis-a-refresher.html#cb386-1" tabindex="-1"></a><span class="fu">ggplot</span>(ncovr, <span class="fu">aes</span>(<span class="at">x =</span> RD90, <span class="at">y =</span> HR90)) <span class="sc">+</span></span>
<span id="cb386-2"><a href="regression-analysis-a-refresher.html#cb386-2" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha=</span>.<span class="dv">2</span>) </span></code></pre></div>
<p><img src="crime_mapping_textbook_files/figure-html/unnamed-chunk-233-1.png" width="672" /></p>
<p>What do you think when looking at this scatterplot? Is there a relationship between the variables? Does it look as if individuals that have a high score on the X axis also have a high score on the Y axis? Or viceversa?</p>
</div>
</div>
<div id="motivating-regression" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> Motivating regression<a href="regression-analysis-a-refresher.html#motivating-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="activity-3-guessing-games" class="section level3 hasAnchor" number="8.2.1">
<h3><span class="header-section-number">8.2.1</span> Activity 3: Guessing games<a href="regression-analysis-a-refresher.html#activity-3-guessing-games" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now, imagine that we play a game. Imagine we have all the respondents waiting in a room, and we randomly call one of them to the stage. You’re sitting in the audience, so that might be you! Well now we ask you to guess the level of homicide (<em>HR90</em>) for a randomly chosen county in the data set. Imagine that we pay £150 to the respondent that gets the closest to the right value. What would you guess if you only have one guess and you knew (as we do) how homicide in the 90s is distributed?</p>
<div class="sourceCode" id="cb387"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb387-1"><a href="regression-analysis-a-refresher.html#cb387-1" tabindex="-1"></a><span class="fu">ggplot</span>(ncovr, <span class="fu">aes</span>(<span class="at">x =</span> HR90)) <span class="sc">+</span> </span>
<span id="cb387-2"><a href="regression-analysis-a-refresher.html#cb387-2" tabindex="-1"></a>  <span class="fu">geom_density</span>() <span class="sc">+</span></span>
<span id="cb387-3"><a href="regression-analysis-a-refresher.html#cb387-3" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">median</span>(ncovr<span class="sc">$</span>HR90), <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>, <span class="at">linewidth =</span> <span class="dv">1</span>, <span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">+</span> <span class="co"># median = 4.377</span></span>
<span id="cb387-4"><a href="regression-analysis-a-refresher.html#cb387-4" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">mean</span>(ncovr<span class="sc">$</span>HR90), <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>, <span class="at">linewidth =</span> <span class="dv">1</span>, <span class="at">color=</span><span class="st">&quot;blue&quot;</span>) <span class="sc">+</span> <span class="co"># mean = 6.183</span></span>
<span id="cb387-5"><a href="regression-analysis-a-refresher.html#cb387-5" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Density estimate, mean and median of homicide rate 1990&quot;</span>)</span></code></pre></div>
<p><img src="crime_mapping_textbook_files/figure-html/unnamed-chunk-234-1.png" width="672" /></p>
<div class="sourceCode" id="cb388"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb388-1"><a href="regression-analysis-a-refresher.html#cb388-1" tabindex="-1"></a><span class="fu">summary</span>(ncovr<span class="sc">$</span>HR90)</span></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   0.000   1.334   4.377   6.183   8.938  71.378</code></pre>
<p>If you only had one shot, you could go for the median, in red, (given the skew) but the mean, in blue, perhaps would be your second best. Most of observations are clustered around those two values, which is another way of saying they are bound to be not too far from them.</p>
<p>Imagine, however, that now when someone is called to the stage, you are told the resource deprivation level of the county, for example, the resource deprivation score = 4 and ask your expectation on the HR90 value of the country. Would you still go for the value of “4.377 (the median of HR90)” as your best guess for the value of the selected county?</p>
<p>I certainly would not go with the overall mean or median as my prediction anymore. If somebody said to me, the value <em>RD90</em> for the selected respondent is 4, we would be more inclined to guess the mean value for the level of homicide with that level of resource deprivation (the conditional mean), rather than the overall mean across all the counties. Wouldn’t you?</p>
<p>If we plot the <strong>conditional means</strong> we can see that the mean of homicide rate for counties that report a value of 4 in <em>RD90</em> is around 22. So you may be better off guessing that.</p>
<pre><code>## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
## ℹ Please use `linewidth` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_lifecycle_warnings()` to see where this
## warning was generated.</code></pre>
<p><img src="crime_mapping_textbook_files/figure-html/unnamed-chunk-236-1.png" width="672" /></p>
<p>Linear regression tackles this problem using a slightly different approach. Rather than focusing on the conditional mean (smoothed or not), it draws a straight line that tries to capture the trend in the data. If we focus in the region of the scatterplot that are less sparse we see that this is an upward trend, suggesting that as resource deprivation increases so does the homicide rate.</p>
<p>Simple linear regression draws a single straight line of predicted values as the model for the data. This line would be a <strong>model</strong>, a <em>simplification</em> of the real world like any other model (e.g., a toy pistol, an architectural drawing, a subway map), that assumes that there is approximately a linear relationship between X and Y. Let’s draw the regression line:</p>
<div class="sourceCode" id="cb391"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb391-1"><a href="regression-analysis-a-refresher.html#cb391-1" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> ncovr, <span class="fu">aes</span>(<span class="at">x =</span> RD90, <span class="at">y =</span> HR90)) <span class="sc">+</span></span>
<span id="cb391-2"><a href="regression-analysis-a-refresher.html#cb391-2" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> .<span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb391-3"><a href="regression-analysis-a-refresher.html#cb391-3" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="co">#This ask for a geom with the regression line, method=lm asks for the linear regression line, se=FALSE ask for just the line to be printed but not the standard error, the other arguments specify the color and thickness of the line</span></span></code></pre></div>
<pre><code>## `geom_smooth()` using formula = &#39;y ~ x&#39;</code></pre>
<p><img src="crime_mapping_textbook_files/figure-html/unnamed-chunk-237-1.png" width="672" /></p>
<p>What that line is doing is giving you guesses (predictions) for the values of homicide based in the information that we have about the level of resource deprivation. It gives you one possible guess for the value of homicide for every possible value of resource deprivation and links them all together in a straight line.</p>
<p>The linear model then is a model that takes the form of the equation of a straight line through the data. The line does not go through all the points. In fact, you can see that it is a slightly less accurate representation of the (smoothed) conditional means:</p>
<p><img src="crime_mapping_textbook_files/figure-html/unnamed-chunk-238-1.png" width="672" /></p>
<p>Our regression line underpredicts at low levels of resource deprivation and does not seem to capture well the variability at higher levels of resource deprivation. But imperfect as a model as it might be it simplifies well the overall growing trend for homicide as resource deprivation increases.</p>
<p>As De Veaux et al (2012: 179) highlight: “like all models of the real world, the line will be wrong, wrong in the sense that it can’t match reality exactly. But it can help us understand how the variables are associated”. A map is never a perfect representation of the world, the same happens with statistical models. Yet, as with maps, models can be helpful.</p>
</div>
</div>
<div id="fitting-a-simple-regression-model" class="section level2 hasAnchor" number="8.3">
<h2><span class="header-section-number">8.3</span> Fitting a simple regression model<a href="regression-analysis-a-refresher.html#fitting-a-simple-regression-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In order to draw a regression line (or in fact any line in a Cartesian coordinate system) we need to know two things:</p>
<ol style="list-style-type: decimal">
<li>We need to know where the line begins, what is the value of Y (our dependent variable) when X (our independent variable) is 0, so that we have a point from which to start drawing the line. The technical name for this point is the <strong>intercept</strong>.</li>
<li>And we need to know the <strong>slope</strong> of that line, that is, how inclined the line is, the angle of the line.</li>
</ol>
<p>If you recall from elementary algebra (and you may not), the equation for any straight line is:
<span class="math inline">\(y = m*x + b\)</span></p>
<p>In statistics we use a slightly different notation, although the equation remains the same:
<span class="math inline">\(y = \beta_0 + \beta_1*x\)</span></p>
<p>We need the origin of the line (<span class="math inline">\(\beta_0\)</span>) and the slope of the line (<span class="math inline">\(\beta_1\)</span>). How does R get the intercept and the slope for the red line? How does R know where to draw this line? We need to estimate these <strong>parameters</strong> (or <strong>coefficients</strong>) from the data. How? We don’t have the time to get into these more mathematical details now. You should study the <a href="http://link.springer.com/chapter/10.1007/978-1-4614-7138-7_3">required reading</a> to understand this (<em>required means it is required, it is not optional</em>)<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>. For now, suffice to say that for linear regression models like the one we cover here, when drawing the line, R tries to minimise the distance from every point in the scatterplot to the regression line using a method called <strong>least squares estimation</strong>.</p>
<div id="activity-4-regressing-homicide-rate-on-deprivation-score" class="section level3 hasAnchor" number="8.3.1">
<h3><span class="header-section-number">8.3.1</span> Activity 4: Regressing homicide rate on deprivation score<a href="regression-analysis-a-refresher.html#activity-4-regressing-homicide-rate-on-deprivation-score" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s apply this to the example of our data - looking at the relationship between homicide rate and deprivation score. In order to fit the model we use the <code>lm()</code> function using the formula specification <span class="math inline">\((Y \sim X)\)</span>. Typically you want to store your regression model in an object, let’s call it <code>fit_1</code>:</p>
<div class="sourceCode" id="cb393"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb393-1"><a href="regression-analysis-a-refresher.html#cb393-1" tabindex="-1"></a>fit_1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(HR90 <span class="sc">~</span> RD90, <span class="at">data =</span> ncovr)</span></code></pre></div>
<p>You will see in your R Studio global environment space that there is a new object called <code>fit_1</code> with 12 elements on it. We can get a sense for what this object is and includes using the functions we introduced in previous weeks:</p>
<div class="sourceCode" id="cb394"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb394-1"><a href="regression-analysis-a-refresher.html#cb394-1" tabindex="-1"></a><span class="fu">class</span>(fit_1)</span></code></pre></div>
<pre><code>## [1] &quot;lm&quot;</code></pre>
<div class="sourceCode" id="cb396"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb396-1"><a href="regression-analysis-a-refresher.html#cb396-1" tabindex="-1"></a><span class="fu">attributes</span>(fit_1)</span></code></pre></div>
<pre><code>## $names
##  [1] &quot;coefficients&quot;  &quot;residuals&quot;     &quot;effects&quot;       &quot;rank&quot;         
##  [5] &quot;fitted.values&quot; &quot;assign&quot;        &quot;qr&quot;            &quot;df.residual&quot;  
##  [9] &quot;xlevels&quot;       &quot;call&quot;          &quot;terms&quot;         &quot;model&quot;        
## 
## $class
## [1] &quot;lm&quot;</code></pre>
<p>R is telling us that this is an object of class <code>lm</code> and that it includes a number of attributes. One of the beauties of R is that you are producing all the results from running the model, putting them in an object, and then giving you the opportunity for using them later on. If you want to simply see the basic results from running the model you can use the <code>summary()</code> function.</p>
<div class="sourceCode" id="cb398"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb398-1"><a href="regression-analysis-a-refresher.html#cb398-1" tabindex="-1"></a><span class="fu">summary</span>(fit_1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = HR90 ~ RD90, data = ncovr)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -17.796  -3.415  -0.719   2.540  67.103 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  6.18286    0.09844   62.81   &lt;2e-16 ***
## RD90         3.77121    0.09846   38.30   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.468 on 3083 degrees of freedom
## Multiple R-squared:  0.3224, Adjusted R-squared:  0.3222 
## F-statistic:  1467 on 1 and 3083 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Or if you prefer more parsimonious presentation you could use the <code>display()</code> function of the <code>arm</code> package:</p>
<div class="sourceCode" id="cb400"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb400-1"><a href="regression-analysis-a-refresher.html#cb400-1" tabindex="-1"></a>arm<span class="sc">::</span><span class="fu">display</span>(fit_1)</span></code></pre></div>
<pre><code>## lm(formula = HR90 ~ RD90, data = ncovr)
##             coef.est coef.se
## (Intercept) 6.18     0.10   
## RD90        3.77     0.10   
## ---
## n = 3085, k = 2
## residual sd = 5.47, R-Squared = 0.32</code></pre>
<p>For now we just want you to focus on the numbers in the “Estimate” (or coef.est) column. The value of 6.18 estimated for the <strong>intercept</strong> is the “predicted” value for Y when X equals zero. This is the predicted value of the homicide rate <em>when resource deprivation has a value of zero</em>.</p>
<div class="sourceCode" id="cb402"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb402-1"><a href="regression-analysis-a-refresher.html#cb402-1" tabindex="-1"></a><span class="fu">summary</span>(ncovr<span class="sc">$</span>RD90)</span></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## -2.4103 -0.6667 -0.2016  0.0000  0.4393  5.5831</code></pre>
<p>RD90 is a variable that has been centered in 0. It has been created by the researchers in such a way that it has a mean value of 0. Since we only have one explanatory variable in the model this corresponds to the mean of the homicide rate, 6.18. In many other contexts the intercept has less of a meaning.</p>
<p>We then need the <span class="math inline">\(\beta_1\)</span> regression coefficient for our independent variable, the value that will shape the <strong>slope</strong> in this scenario. This value is 3.77. This estimated regression coefficient for our independent variable has a convenient interpretation. When the value is positive, it tells us that <em>for every one unit increase in X there is a</em> <span class="math inline">\(\beta_1\)</span> <em>increase on Y</em>. If the coefficient is negative then it represents a decrease on Y. Here, we can read it as “for every one unit increase in the resource deprivation score, there is a 3.77 unit increase in the homicide rate.”</p>
<p>Knowing these two parameters not only allows us to draw the line, we can also solve for any given value of X. Let’s go back to our guess-the-homicide-rate game. Imagine we tell you the level of resource deprivation is 1. What would be your best bet now? We can simply go back to our regression line equation and insert the estimated parameters:</p>
<p><span class="math inline">\(y = \beta_0 + \beta_1x\)</span></p>
<p><span class="math inline">\(y = 6.18 + 3.77 \times 1\)</span></p>
<p><span class="math inline">\(y = 9.95\)</span></p>
<p>Or if you don’t want to do the calculation yourself, you can use the <code>predict</code> function (differences are due to rounding error):</p>
<div class="sourceCode" id="cb404"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb404-1"><a href="regression-analysis-a-refresher.html#cb404-1" tabindex="-1"></a><span class="fu">predict</span>(fit_1, <span class="fu">data.frame</span>(<span class="at">RD90 =</span> <span class="fu">c</span>(<span class="dv">1</span>))) <span class="co">#First you name your stored model and then you identify the new data (which has to be in a data frame format and with a variable name matching the one in the original data set)</span></span></code></pre></div>
<pre><code>##        1 
## 9.954065</code></pre>
<p>This is the expected value of Y, homicide rate, when X, resource deprivation is 1 <strong>according to our model</strong> (according to our simplification of the real world, our simplification of the whole cloud of points into just one straight line). Look back at the scatterplot we produced earlier with the red line. Does it look as if the red line when X is 1 corresponds to a value of Y of 9.95?</p>
</div>
</div>
<div id="residuals-revisited-r-squared" class="section level2 hasAnchor" number="8.4">
<h2><span class="header-section-number">8.4</span> Residuals revisited: R squared<a href="regression-analysis-a-refresher.html#residuals-revisited-r-squared" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the output above we saw there was something called the residuals. The residuals are the differences between the observed values of Y for each case minus the predicted or expected value of Y, in other words the distances between each point in the dataset and the regression line (see the visual example below).</p>
<p><img src="img/mYzliZjY4ZDc0NjI3YWQ3YWVlM2MzZmUzN2MwOWY.jpg" /></p>
<p>You see that we have our line, which is our predicted values, and then we have the black dots which are our actually observed values. The distance between them is essentially the amount by which we were wrong, and all these distances between observed and predicted values are our residuals. Least square estimation essentially aims to reduce the average of the squares of all these distances: that’s how it draws the line.</p>
<p>Why do we have residuals? Well, think about it. The fact that the line is not a perfect representation of the cloud of points makes sense, doesn’t it? You cannot predict perfectly what the value of Y is for every observation just by looking ONLY at their level of resource deprivation! This line only uses information regarding resource deprivation. This means that there’s bound to be some difference between our predicted level of homicide given our knowledge of deprivation (the regression line) and the actual level of homicide (the actual location of the points in the scatterplot). There are other things that matter not being taken into account by our model to predict the values of Y. There are other things that surely matter in terms of understanding homicide. And then, of course, we have measurement error and other forms of noise.</p>
<p>We can re-write our equation like this if we want to represent each value of Y (rather than the predicted value of Y) then:</p>
<p><span class="math inline">\(y = \beta_0 + \beta_1x + e(residuals)\)</span></p>
<p>The residuals capture how much variation is unexplained, how much we still have to learn if we want to understand variation in Y. A good model tries to maximise explained variation and reduce the magnitude of the residuals.</p>
<p>We can use information from the residuals to produce a measure of effect size, of how good our model is in predicting variation in our dependent variables. Remember our game where we try to guess homicide (Y)? If we did not have any information about X our best bet for Y would be the mean of Y. The regression line aims to improve that prediction. By knowing the values of X we can build a regression line that aims to get us closer to the actual values of Y (look at the Figure below).</p>
<p><img src="img/weight2.png" /></p>
<p>The distance between the mean (our best guess without any other piece of information) and the observed value of Y is what we call the <strong>total variation</strong>. The residual is the difference between our predicted value of Y and the observed value of Y. This is what we cannot explain (i.e. variation in Y that is <em>unexplained</em>). The difference between the mean value of Y and the expected value of Y (the value given by our regression line) is how much better we are doing with our prediction by using information about X (i.e. in our previous example it would be variation in Y that can be <em>explained</em> by knowing about resource deprivation). <!---Not sure if this sentence makes sense?---> How much closer the regression line gets us to the observed values. We can then contrast these two different sources of variation (explained and unexplained) to produce a single measure of how good our model is. The formula is as follows:</p>
<p><span class="math inline">\(R^2 = \dfrac{SSR}{SST} = \dfrac{\Sigma(\hat y_i - \bar y )^2}{\Sigma(y_i - \bar y )^2}\)</span></p>
<p>All this formula is doing is taking a ratio of the explained variation (the squared differences between the regression line and the mean of Y for each observation) by the total variation (the squared differences of the observed values of Y for each observation from the mean of Y). This gives us a measure of the <strong>percentage of variation in Y that is “explained” by X</strong>. If this sounds familiar is because it is a measure similar to eta squared (<span class="math inline">\(\eta^2\)</span>) in ANOVA.</p>
<div id="activity-5-residuals-for-our-homicide-rate-model" class="section level3 hasAnchor" number="8.4.1">
<h3><span class="header-section-number">8.4.1</span> Activity 5: Residuals for our homicide rate model<a href="regression-analysis-a-refresher.html#activity-5-residuals-for-our-homicide-rate-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now then we can take this value as a measure of the strength of our model. If you look at the R output you will see that the <span class="math inline">\(R^2\)</span> for our model was .32 (look at the multiple R square value in the output). We can say that our model explains 32% of the variance in homicide. When doing regression, you will often find that regression models with aggregate data such as county level data will give you better results than when dealing with individuals. It is much harder understanding individual variation than county level variation.</p>
<div class="sourceCode" id="cb406"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb406-1"><a href="regression-analysis-a-refresher.html#cb406-1" tabindex="-1"></a><span class="co">#As an aside, and to continue emphasising your appreciation of the object oriented nature of R, when we run the summary() function we are simply generating a list object of the class summary.lm.</span></span>
<span id="cb406-2"><a href="regression-analysis-a-refresher.html#cb406-2" tabindex="-1"></a><span class="fu">attributes</span>(<span class="fu">summary</span>(fit_1))</span></code></pre></div>
<pre><code>## $names
##  [1] &quot;call&quot;          &quot;terms&quot;         &quot;residuals&quot;     &quot;coefficients&quot; 
##  [5] &quot;aliased&quot;       &quot;sigma&quot;         &quot;df&quot;            &quot;r.squared&quot;    
##  [9] &quot;adj.r.squared&quot; &quot;fstatistic&quot;    &quot;cov.unscaled&quot; 
## 
## $class
## [1] &quot;summary.lm&quot;</code></pre>
<div class="sourceCode" id="cb408"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb408-1"><a href="regression-analysis-a-refresher.html#cb408-1" tabindex="-1"></a><span class="co">#This means that we can access its elements if so we wish. So, for example, to obtain just the R Squared, we could ask for:</span></span>
<span id="cb408-2"><a href="regression-analysis-a-refresher.html#cb408-2" tabindex="-1"></a><span class="fu">summary</span>(fit_1)<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.3224335</code></pre>
<p>Knowing how to interpret this is important. <span class="math inline">\(R^2\)</span> ranges from 0 to 1. The greater it is the more powerful our model is, the more explaining we are doing, the better we are able to account for variation in our outcome Y with our input. In other words, the stronger the relationship is between Y and X. As with all the other measures of effect size, interpretation is a matter of judgement. You are advised to see what other researchers report in relation to the particular outcome that you may be exploring.</p>
<p>Weisburd and Britt (2009: 437) suggest that in criminal justice you rarely see values for <span class="math inline">\(R^2\)</span> greater than .40. Thus, if your <span class="math inline">\(R^2\)</span> is larger than .40, you can assume you have a powerful model. When, on the other hand, <span class="math inline">\(R^2\)</span> is lower than .15 or .2 the model is likely to be viewed as relatively weak. Our observed r squared here is rather poor. There is considerable room for improvement if we want to develop a better model to explain fear of violent crime<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>. In any case, many people would argue that <span class="math inline">\(R^2\)</span> is a bit overrated. You need to be aware of what it measures and the context in which you are using it. Read <a href="http://blog.minitab.com/blog/adventures-in-statistics/how-high-should-r-squared-be-in-regression-analysis">here</a> for some additional detail.</p>
</div>
</div>
<div id="inference-with-regression" class="section level2 hasAnchor" number="8.5">
<h2><span class="header-section-number">8.5</span> Inference with regression<a href="regression-analysis-a-refresher.html#inference-with-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In real applications, we have access to a set of observations from which we can compute the least squares line, but the population regression line is unobserved. So our regression line is one of many that could be estimated. A different sample would produce a different regression line. The same sort of ideas that we introduced when discussing the estimation of sample means or proportions also apply here. if we estimate <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> from a particular sample, then our estimates won’t be exactly equal to <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> in the population. But if we could average the estimates obtained over a very large number of data sets, the average of these estimates would equal the coefficients of the regression line in the population.</p>
<p>We can compute standard errors for the regression coefficients to quantify our uncertainty about these estimates. These standard errors can in turn be used to produce confidence intervals. This would require us to assume that the residuals are normally distributed. As seen in the image, and for a simple regression model, you are assuming that the values of Y are approximately normally distributed for each level of X:</p>
<p><img src="img/Doe4.3.png" /></p>
<p>In those circumstances we can trust the confidence intervals that we can draw around the regression line as in the image below:</p>
<p><img src="img/SimpleLinearRegressionJags-ICON-FREQ-EST.png" title="Image taken from John Krushcke blog http://doingbayesiandataanalysis.blogspot.co.uk/" /></p>
<p>The dark-blue line marks the best fit. The two dark-pink lines mark the limits of the confidence interval. The light-pink lines show the sampling distributions around each of the confidence-interval limits (the many regression lines that would result from repeated sampling); notice that the best-fit line falls at the extreme of each sampling distribution.</p>
<p>You can also then perform a standard hypothesis test on the coefficients. As we saw before when summarising the model, R will compute the standard errors and a t test for each of the coefficients.</p>
<div class="sourceCode" id="cb410"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb410-1"><a href="regression-analysis-a-refresher.html#cb410-1" tabindex="-1"></a><span class="fu">summary</span>(fit_1)<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>##             Estimate Std. Error  t value      Pr(&gt;|t|)
## (Intercept) 6.182860 0.09844166 62.80735  0.000000e+00
## RD90        3.771206 0.09845761 38.30283 6.535551e-263</code></pre>
<p>In our example, we can see that the coefficient for our predictor here is statistically significant<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>.</p>
<p>We can also obtain confidence intervals for the estimated coefficients using the <code>confint()</code> function:</p>
<div class="sourceCode" id="cb412"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb412-1"><a href="regression-analysis-a-refresher.html#cb412-1" tabindex="-1"></a><span class="fu">confint</span>(fit_1)</span></code></pre></div>
<pre><code>##                2.5 %   97.5 %
## (Intercept) 5.989842 6.375877
## RD90        3.578156 3.964255</code></pre>
</div>
<div id="fitting-regression-with-categorical-predictors" class="section level2 hasAnchor" number="8.6">
<h2><span class="header-section-number">8.6</span> Fitting regression with categorical predictors<a href="regression-analysis-a-refresher.html#fitting-regression-with-categorical-predictors" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>So far we have explained regression using a numeric input. It turns out we can also use regression with categorical explanatory variables. It is quite straightforward to run it.</p>
<div id="activity-6-homicide-rates-in-the-south-v-the-north" class="section level3 hasAnchor" number="8.6.1">
<h3><span class="header-section-number">8.6.1</span> Activity 6: Homicide rates in the South v the North<a href="regression-analysis-a-refresher.html#activity-6-homicide-rates-in-the-south-v-the-north" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There is only one categorical explanatory variable in this dataset, a binary indicator that indicates whether the county is in a Southern State or not. We can also explore this relationship using regression and a regression line. This is how you would express the model:</p>
<div class="sourceCode" id="cb414"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb414-1"><a href="regression-analysis-a-refresher.html#cb414-1" tabindex="-1"></a><span class="co">#We use the as.factor function to tell R that SOUTH is a categorical variable</span></span>
<span id="cb414-2"><a href="regression-analysis-a-refresher.html#cb414-2" tabindex="-1"></a>fit_2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(HR90 <span class="sc">~</span> <span class="fu">as.factor</span>(SOUTH), <span class="at">data=</span>ncovr)</span></code></pre></div>
<p>Notice that there is nothing different in how we ask for the model. And see below the regression line:</p>
<p><img src="crime_mapping_textbook_files/figure-html/unnamed-chunk-249-1.png" width="672" /></p>
<p>Although in the plot we still see a line, what we are really estimating here is the average of HR90 for each of the two categories.
Let’s have a look at the results:</p>
<div class="sourceCode" id="cb415"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb415-1"><a href="regression-analysis-a-refresher.html#cb415-1" tabindex="-1"></a><span class="fu">summary</span>(fit_2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = HR90 ~ as.factor(SOUTH), data = ncovr)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -9.549 -3.342 -1.172  1.931 68.036 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)         3.3416     0.1437   23.25   &lt;2e-16 ***
## as.factor(SOUTH)1   6.2077     0.2124   29.22   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.878 on 3083 degrees of freedom
## Multiple R-squared:  0.2169, Adjusted R-squared:  0.2167 
## F-statistic:   854 on 1 and 3083 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>As you will see the output does not look too different. But notice that in the print out you see how the row with the coefficient and other values for our input variable <code>SOUTH</code> we see that R is printing <code>1</code>. What does this mean?</p>
<p>It turns out that a linear regression model with just one dichotomous categorical predictor is just the equivalent of a t test. When you only have one predictor the value of the intercept is the mean value of the <strong>reference category</strong> and the coefficient for the slope tells you how much higher (if it is positive) or how much lower (if it is negative) is the mean value for the other category in your factor.</p>
<p>The reference category is the one for which R does not print the <em>level</em> next to the name of the variable for which it gives you the regression coefficient. Here we see that the named level is “1”. That’s telling you that the reference category here is “0”. If you look at the codebook you will see that 1 means the county is in a Southern state. Therefore the Y intercept in this case is the mean value of fear of violent crime for the northern counties, whereas the coefficient for the slope is telling you how much higher (since it is a positive value) the mean value is for the southern counties. Don’t believe me?</p>
<div class="sourceCode" id="cb417"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb417-1"><a href="regression-analysis-a-refresher.html#cb417-1" tabindex="-1"></a><span class="fu">mean</span>(ncovr<span class="sc">$</span>HR90[ncovr<span class="sc">$</span>SOUTH <span class="sc">==</span> <span class="dv">0</span>], <span class="at">na.rm=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## [1] 3.341614</code></pre>
<div class="sourceCode" id="cb419"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb419-1"><a href="regression-analysis-a-refresher.html#cb419-1" tabindex="-1"></a><span class="fu">mean</span>(ncovr<span class="sc">$</span>HR90[ncovr<span class="sc">$</span>SOUTH <span class="sc">==</span> <span class="dv">1</span>], <span class="at">na.rm=</span><span class="cn">TRUE</span>) <span class="sc">-</span> <span class="fu">mean</span>(ncovr<span class="sc">$</span>HR90[ncovr<span class="sc">$</span>SOUTH <span class="sc">==</span> <span class="dv">0</span>], <span class="at">na.rm=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## [1] 6.207679</code></pre>
<p>So, to reiterate, for a binary predictor, the coefficient is nothing else than the difference between the mean of the two levels in your factor variable, between the averages in your two groups.</p>
<p>With categorical variables encoded as <strong>factors</strong> you always have a situation like this: a reference category and then as many additional coefficients as there are additional levels in your categorical variable. Each of these additional categories is included into the model as <strong>“dummy” variables</strong>. Here our categorical variable has two levels, thus we have only one dummy variable. There will always be one fewer dummy variable than the number of levels. The level with no dummy variable, northern counties in this example, is known as the <strong>reference category</strong> or the <strong>baseline</strong>.</p>
<p>It turns out then that the regression table is printing out for us a t test of statistical significance for every input in the model. If we look at the table above this t value is 29.22 and the p value associated with it is near 0. This is indeed considerably lower than the conventional significance level of 0.05. So we could conclude that the probability of obtaining this value if the null hypothesis is true is very low. The r squared is not too bad either, although lower than we saw when using resource deprivation.</p>
</div>
</div>
<div id="motivating-multiple-regression" class="section level2 hasAnchor" number="8.7">
<h2><span class="header-section-number">8.7</span> Motivating multiple regression<a href="regression-analysis-a-refresher.html#motivating-multiple-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>So we have seen that we can fit models with just one predictor. We can build better models by expanding the number of predictors (although keep in mind you should also aim to build models as parsimonious (i.e. as simply) as possible).</p>
<p>Another reason why it is important to think about additional variables in your model is to control for spurious correlations (although here you may also want to use your common sense when selecting your variables!). You must have heard before that correlation does not equal causation. Just because two things are associated we cannot assume that one is the cause of the other. Typically we see how the pilots switch the secure the seatbelt button when there is turbulence. These two things are associated, they tend to come together. But the pilots are not causing the turbulence by pressing a switch! The world is full of <strong>spurious correlations</strong>, associations between two variables that should not be taken too seriously. You can explore a few <a href="http://tylervigen.com/">here</a>. It’s funny.</p>
<p>Looking only at covariation between a pair of variables can be misleading. It may lead you to conclude that a relationship is more important than it really is. This is no trivial matter, it’s one of the most important ones we confront in research and policy<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>.</p>
<p>It’s not an exaggeration to say that most quantitative explanatory research is about trying to control for the presence of <strong>confounders</strong>, variables that may explain away observed associations. Think about any criminology question: Does marriage reduces crime? Or is it that people that get married are different from those that don’t (and are those pre-existing differences associated with less crime)? Do gangs lead to more crime? Or is it that young people that join gangs are more likely to be offenders to start with? Are the police being racist when they stop and search more members of ethnic minorities? Or is it that there are other factors (i.e. offending, area of residence, time spent in the street) that, once controlled, would mean there is no ethnic dis-proportionality in stop and searches? Does a particular program reduce crime? Or is the observed change due to something else?</p>
<p>These things also matter for policy. Wilson and Kelling, for example, argued that signs of incivility (or antisocial behaviour) in a community lead to more serious forms of crime later on as people withdraw to the safety of their homes when they see those signs of incivilities and this leads to a reduction in informal mechanisms of social control. All the policies to tackle antisocial behaviour in this country are very much informed by this model and were heavily influenced by broken windows theory.</p>
<p>But is the model right? Sampson and Raudenbush argue it is not entirely correct. They argue, and tried to show, that there are other confounding factors (poverty, collective efficacy) that explain the association of signs of incivility and more serious crime. In other words, the reason why you see antisocial behaviour in the same communities that you see crime is because other structural factors explain both of those outcomes. They also argue that perceptions of antisocial behaviour are not just produced by observed antisocial behaviour but also by stereotypes about social class and race. If you believe them, then the policy implications are that only tackling antisocial behaviour won’t help you to reduce crime (as Wilson and Kelling have argued). So as you can see this stuff matters for policy not just for theory.</p>
<p>Multiple regression is one way of checking the relevance of competing explanations. You could set up a model where you try to predict crime levels with an indicator of broken windows and an indicator of structural disadvantage. If after controlling for structural disadvantage you see that the regression coefficient for broken windows is still significant you may be onto something, particularly if the estimated effect is still large. If, on the other hand, the t test for the regression coefficient of your broken windows variable is no longer significant, then you may be tempted to think that perhaps Sampson and Raudenbush were onto something.</p>
</div>
<div id="fitting-and-interpreting-a-multiple-regression-model" class="section level2 hasAnchor" number="8.8">
<h2><span class="header-section-number">8.8</span> Fitting and interpreting a multiple regression model<a href="regression-analysis-a-refresher.html#fitting-and-interpreting-a-multiple-regression-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>It could not be any easier to fit a multiple regression model. You simply modify the formula in the <code>lm()</code> function by adding terms for the additional inputs.</p>
<div id="activity-7-better-explaining-homicide-rates" class="section level3 hasAnchor" number="8.8.1">
<h3><span class="header-section-number">8.8.1</span> Activity 7: Better explaining homicide rates<a href="regression-analysis-a-refresher.html#activity-7-better-explaining-homicide-rates" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s try this with our data, using two predictors, the deprivation score and whether the county is in the north or the south to explain homicide rates.</p>
<div class="sourceCode" id="cb421"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb421-1"><a href="regression-analysis-a-refresher.html#cb421-1" tabindex="-1"></a>ncovr<span class="sc">$</span>SOUTH_f <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(ncovr<span class="sc">$</span>SOUTH)</span>
<span id="cb421-2"><a href="regression-analysis-a-refresher.html#cb421-2" tabindex="-1"></a>fit_3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(HR90 <span class="sc">~</span> RD90 <span class="sc">+</span> SOUTH_f, <span class="at">data=</span>ncovr)</span>
<span id="cb421-3"><a href="regression-analysis-a-refresher.html#cb421-3" tabindex="-1"></a><span class="fu">summary</span>(fit_3)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = HR90 ~ RD90 + SOUTH_f, data = ncovr)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -16.480  -2.996  -0.576   2.216  68.151 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   4.7270     0.1394   33.90   &lt;2e-16 ***
## RD90          2.9649     0.1108   26.77   &lt;2e-16 ***
## SOUTH_f1      3.1809     0.2223   14.31   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.295 on 3082 degrees of freedom
## Multiple R-squared:  0.3647, Adjusted R-squared:  0.3642 
## F-statistic: 884.4 on 2 and 3082 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>With more than one input, you need to ask yourself whether all of the regression coefficients are zero. This hypothesis is tested with a F test. Again we are assuming the residuals are normally distributed, though with large samples the F statistic approximates the F distribution.</p>
<p>You see the F test printed at the bottom of the summary output and the associated p value, which in this case is way below the conventional .05 that we use to declare statistical significance and reject the null hypothesis. At least one of our inputs must be related to our response variable.</p>
<p>Notice that the table printed also reports a t test for each of the predictors. These are testing whether each of these predictors is associated with the response variable when adjusting for the other variables in the model. They report the “partial effect of adding that variable to the model” (James et al. 2014: 77). In this case we can see that both variables seem to be significantly associated with the response variable.</p>
<p>If we look at the r squared we can now see that it is higher than before. r squared will always increase as a consequence of adding new variables, even if the new variables added are weakly related to the response variable.</p>
<p>We see that the coefficients for the predictors change somehow, it goes down a bit for <em>RD90</em> and it halves for <em>SOUTH</em>. <strong>But their interpretation now changes</strong>. A common interpretation is that now the regression for each variable tells you about changes in Y related to that variable <strong>when the other variables in the model are held constant</strong>. So, for example, you could say the coefficient for <em>RD90</em> represents the increase in homicide for every one-unit increase in the measure of resource deprivation <em>when holding all other variables in the model constant</em> (in this case that refers to holding constant <em>SOUTH</em>). But this terminology can be a bit misleading.</p>
<p>Other interpretations are also possible and are more generalizable. Gelman and Hill (2007: p. 34) emphasise what they call the <em>predictive interpretation</em> that considers how “the outcome variable differs, on average, when comparing two groups of units that differ by 1 in the relevant predictor while being identical in all the other predictors”. So <a href="http://andrewgelman.com/2013/01/05/understanding-regression-models-and-regression-coefficients/">if you’re regressing y on u and v, the coefficient of u is the average difference in y per difference in u, comparing pairs of items that differ in u but are identical in v</a>.</p>
<p>So, for example, in this case we could say that comparing counties that have the same level of resource deprivation but that differed in whether they are North or South, the model predicts an expected difference of 3.18 in their homicide rate. And that respondents that do not vary in whether they are North or South, but that differ by one point in the level of resource deprivation, we would expect to see a difference of 2.96 in their homicide rate. So we are interpreting the regression slopes <strong>as comparisons of cases that differ in one predictor while being at the same levels of the other predictors</strong>.</p>
<p>As you can see, interpreting regression coefficients can be kind of tricky<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>. The relationship between the response Y and any one explanatory variable can change greatly depending on what other explanatory variables are present in the model.</p>
<p>For example, if you contrast this model with the one we run with only <em>SOUTH</em> as a predictor you will notice the intercept has changed. You can no longer read the intercept as the mean value of homicide rate for Northern counties. <em>Adding predictors to the model changes their meaning</em>. Now the intercept indicates the value of homicide for southern counties that score 0 in <em>RD90</em>. In this case you have cases that meet this condition (equal zero in all your predictors), but often you may not have any case that does meet the definition of the intercept. More often than not, then, there is not much value in bothering to interpret the intercept.</p>
<p>Something you need to be particularly careful about is to not interpret the coefficients in a causal manner. Unless your data come from an experiment, this is unlikely to be helpful. With observational data regression coefficients should not be read as indicating causal relations. This sort of textbook warning is, however, often neglectfully ignored by professional researchers. Often authors carefully draw sharp distinctions between causal and correlational claims when discussing their data analysis, but then interpret the correlational patterns in a totally causal way in their conclusion section. This is what is called the <a href="http://junkcharts.typepad.com/numbersruleyourworld/2012/07/the-causation-creep.html">causation</a> or <a href="http://www.carlislerainey.com/2012/12/05/another-example-of-causal-creep/">causal</a> creep. Beware. Don’t do this, as tempting as it may be.</p>
<p>Comparing the simple models with this more complex model we could say that adjusting for <em>SOUTH</em> does not really change the impact of <em>RD90</em> in homicide, but that adjusting for resource deprivation halves the impact of the regional effect on homicide.</p>
</div>
</div>
<div id="presenting-your-regression-results." class="section level2 hasAnchor" number="8.9">
<h2><span class="header-section-number">8.9</span> Presenting your regression results.<a href="regression-analysis-a-refresher.html#presenting-your-regression-results." class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Communicating your results in a clear manner is incredibly important. We have seen the tabular results produced by R. If you want to use them in a paper you may need to do some tidying up of those results. There are a number of packages (<code>textreg</code>, <code>stargazer</code>) that automate that process. They take your <code>lm</code> objects and produce tables that you can put straight into your reports or papers. One popular trend in presenting results is the <strong>coefficient plot</strong> as an alternative to the table of regression coefficients. There are various ways of producing coefficient plots with R for a variety of models. See <a href="https://www.r-statistics.com/2010/07/visualization-of-regression-coefficients-in-r/">here</a> or <a href="http://felixhaass.de/dataviz_ggplot2/session4.html">here</a>, for example.</p>
<div id="activity-8-plotting-your-results" class="section level3 hasAnchor" number="8.9.1">
<h3><span class="header-section-number">8.9.1</span> Activity 8: Plotting your results<a href="regression-analysis-a-refresher.html#activity-8-plotting-your-results" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We are going to use instead the <code>plot_model()</code> function of the <code>sjPlot</code> package, that makes it easier to produce these sorts of plots. You can find a more detailed tutorial about this function <a href="https://strengejacke.wordpress.com/2017/10/23/one-function-to-rule-them-all-visualization-of-regression-models-in-rstats-w-sjplot/">here</a>. See below for an example:</p>
<div class="sourceCode" id="cb423"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb423-1"><a href="regression-analysis-a-refresher.html#cb423-1" tabindex="-1"></a><span class="fu">library</span>(sjPlot)</span></code></pre></div>
<p>Let’s try with a more complex example:</p>
<div class="sourceCode" id="cb424"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb424-1"><a href="regression-analysis-a-refresher.html#cb424-1" tabindex="-1"></a>fit_4 <span class="ot">&lt;-</span> <span class="fu">lm</span>(HR90 <span class="sc">~</span> RD90 <span class="sc">+</span> SOUTH_f <span class="sc">+</span> DV90 <span class="sc">+</span> MA90 <span class="sc">+</span> PS90, <span class="at">data=</span>ncovr)</span>
<span id="cb424-2"><a href="regression-analysis-a-refresher.html#cb424-2" tabindex="-1"></a><span class="fu">plot_model</span>(fit_4, <span class="at">breakLabelsAt =</span> <span class="dv">30</span>)</span></code></pre></div>
<p><img src="crime_mapping_textbook_files/figure-html/unnamed-chunk-254-1.png" width="672" /></p>
<p>What you see plotted here is the point estimates (the circles), the confidence intervals around those estimates (the longer the line the less precise the estimate), and the colours represent whether the effect is negative (red) or positive (blue). There are other packages that also provide similar functionality, like the <code>dotwhisker</code> package that you may want to explore, see more details <a href="https://cran.r-project.org/web/packages/dotwhisker/vignettes/dotwhisker-vignette.html">here</a>.</p>
<p>The <code>sjPlot</code> package also allows you to produce html tables for more professional presentation of your regression tables. For this we use the <code>tab_model()</code> function. This kind of tabulation may be particularly helpful for your final assignment.</p>
<div class="sourceCode" id="cb425"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb425-1"><a href="regression-analysis-a-refresher.html#cb425-1" tabindex="-1"></a><span class="fu">tab_model</span>(fit_4)</span></code></pre></div>
<table style="border-collapse:collapse; border:none;">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="3" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
HR 90
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
4.20
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
2.27 – 6.13
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
RD90
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
3.20
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
2.98 – 3.42
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
SOUTH f [1]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
2.60
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
2.18 – 3.02
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
DV90
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.48
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.37 – 0.58
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
MA90
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.08
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.13 – -0.02
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>0.006</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
PS90
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.26
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.07 – 1.46
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="3">
3085
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
R<sup>2</sup> / R<sup>2</sup> adjusted
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
0.426 / 0.425
</td>
</tr>
</table>
<p>As before you can further customise this table. Let’s change for example the name that is displayed for the dependent variable.</p>
<div class="sourceCode" id="cb426"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb426-1"><a href="regression-analysis-a-refresher.html#cb426-1" tabindex="-1"></a><span class="fu">tab_model</span>(fit_4, <span class="at">dv.labels =</span> <span class="st">&quot;Homicide rate 1990&quot;</span>)</span></code></pre></div>
<table style="border-collapse:collapse; border:none;">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="3" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
Homicide rate 1990
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
4.20
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
2.27 – 6.13
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
RD90
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
3.20
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
2.98 – 3.42
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
SOUTH f [1]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
2.60
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
2.18 – 3.02
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
DV90
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.48
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.37 – 0.58
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
MA90
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.08
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.13 – -0.02
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>0.006</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
PS90
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.26
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.07 – 1.46
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="3">
3085
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
R<sup>2</sup> / R<sup>2</sup> adjusted
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
0.426 / 0.425
</td>
</tr>
</table>
<p>Or you could change the labels for the independent variables:</p>
<div class="sourceCode" id="cb427"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb427-1"><a href="regression-analysis-a-refresher.html#cb427-1" tabindex="-1"></a><span class="fu">tab_model</span>(fit_4, <span class="at">pred.labels =</span> <span class="fu">c</span>(<span class="st">&quot;(Intercept)&quot;</span>, <span class="st">&quot;Resource deprivation&quot;</span>, <span class="st">&quot;South&quot;</span>, <span class="st">&quot;Percent divorced males&quot;</span>, <span class="st">&quot;Median age&quot;</span>, <span class="st">&quot;Population structure&quot;</span>), <span class="at">dv.labels =</span> <span class="st">&quot;Homicide rate&quot;</span>)</span></code></pre></div>
<table style="border-collapse:collapse; border:none;">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="3" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
Homicide rate
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
4.20
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
2.27 – 6.13
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
Resource deprivation
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
3.20
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
2.98 – 3.42
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
South
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
2.60
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
2.18 – 3.02
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
Percent divorced males
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.48
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.37 – 0.58
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
Median age
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.08
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.13 – -0.02
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>0.006</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
Population structure
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.26
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.07 – 1.46
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="3">
3085
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
R<sup>2</sup> / R<sup>2</sup> adjusted
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
0.426 / 0.425
</td>
</tr>
</table>
<p>Visual display of the effects of the variables in the model are particularly helpful. The <code>effects</code> package allows us to produce plots to visualise these relationships (when adjusting for the other variables in the model). Here’s an example going back to our model fit_3 which contained <em>SOUTH</em> and <em>RD90</em> predictor variables:</p>
<div class="sourceCode" id="cb428"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb428-1"><a href="regression-analysis-a-refresher.html#cb428-1" tabindex="-1"></a><span class="fu">library</span>(effects)</span>
<span id="cb428-2"><a href="regression-analysis-a-refresher.html#cb428-2" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">allEffects</span>(fit_3), <span class="at">ask=</span><span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="crime_mapping_textbook_files/figure-html/unnamed-chunk-258-1.png" width="672" /></p>
<p>Notice that the line has a confidence interval drawn around it and that the predicted means for southern and northern counties (when controlling for <em>RD90</em>) also have a confidence interval.</p>
</div>
</div>
<div id="rescaling-input-variables-to-assist-interpretation" class="section level2 hasAnchor" number="8.10">
<h2><span class="header-section-number">8.10</span> Rescaling input variables to assist interpretation<a href="regression-analysis-a-refresher.html#rescaling-input-variables-to-assist-interpretation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The interpretation or regression coefficients is sensitive to the scale of measurement of the predictors. This means one cannot compare the magnitude of the coefficients to compare the relevance of variables to predict the response variable. Let’s look at the more recent model, how can we tell what predictors have a stronger effect?</p>
<div class="sourceCode" id="cb429"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb429-1"><a href="regression-analysis-a-refresher.html#cb429-1" tabindex="-1"></a><span class="fu">summary</span>(fit_4)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = HR90 ~ RD90 + SOUTH_f + DV90 + MA90 + PS90, data = ncovr)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -15.740  -2.588  -0.678   1.708  69.180 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  4.20350    0.98475   4.269 2.03e-05 ***
## RD90         3.19923    0.11167  28.648  &lt; 2e-16 ***
## SOUTH_f1     2.59975    0.21557  12.060  &lt; 2e-16 ***
## DV90         0.47594    0.05308   8.967  &lt; 2e-16 ***
## MA90        -0.07609    0.02743  -2.774  0.00557 ** 
## PS90         1.26451    0.10047  12.587  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.035 on 3079 degrees of freedom
## Multiple R-squared:  0.4262, Adjusted R-squared:  0.4252 
## F-statistic: 457.3 on 5 and 3079 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>We just cannot. One way of dealing with this is by rescaling the input variables. A common method involves subtracting the mean and dividing by the standard deviation of each numerical input. The coefficients in these models is the expected difference in the response variable, comparing units that differ by one standard deviation in the predictor while adjusting for other predictors in the model.</p>
<p>Instead, <a href="http://www.stat.columbia.edu/~gelman/research/published/standardizing7.pdf">Gelman (2008)</a> has proposed dividing each numeric variables <em>by two times its standard deviation</em>, so that the generic comparison is with inputs equal to plus/minus one standard deviation. As Gelman explains the resulting coefficients are then comparable to untransformed binary predictors. The implementation of this approach in the <code>arm</code> package subtracts the mean of each binary input while it subtracts the mean and divides by two standard deviations for every numeric input.</p>
<p>The way we would obtain these rescaled inputs uses the <code>standardize()</code> function of the <code>arm</code> package, that takes as an argument the name of the stored fit model.</p>
<div class="sourceCode" id="cb431"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb431-1"><a href="regression-analysis-a-refresher.html#cb431-1" tabindex="-1"></a>arm<span class="sc">::</span><span class="fu">standardize</span>(fit_4)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = HR90 ~ z.RD90 + c.SOUTH_f + z.DV90 + z.MA90 + z.PS90, 
##     data = ncovr)
## 
## Coefficients:
## (Intercept)       z.RD90    c.SOUTH_f       z.DV90       z.MA90       z.PS90  
##      6.1829       6.3985       2.5998       1.6497      -0.5478       2.5290</code></pre>
<p>Notice the main change affects the numerical predictors. The unstandardised coefficients are influenced by the degree of variability in your predictors, which means that typically they will be larger for your binary inputs. With unstandardised coefficients you are comparing complete change in one variable (whether one is a Southern county or not) with one-unit changes in your numerical variable, which may not amount to much change. So, by putting in a comparable scale, you avoid this problem.</p>
<p>Standardising in the way described here will help you to make fairer comparisons. These standardised coefficients are comparable in a way that the unstandardised coefficients are not. We can now see what inputs have a comparatively stronger effect. It is very important to realise, though, that one <strong>should not</strong> compare standardised coefficients <em>across different models</em>.</p>
</div>
<div id="testing-conditional-hypothesis-interactions" class="section level2 hasAnchor" number="8.11">
<h2><span class="header-section-number">8.11</span> Testing conditional hypothesis: interactions<a href="regression-analysis-a-refresher.html#testing-conditional-hypothesis-interactions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the social sciences there is a great interest in what are called conditional hypothesis or interactions. Many of our theories do not assume simply <strong>additive effects</strong> but <strong>multiplicative effects</strong>.For example, <a href="http://euc.sagepub.com/content/8/5/401.short">Wikstrom and his colleagues (2011)</a> suggest that the threat of punishment only affects the probability of involvement on crime for those that have a propensity to offend but are largely irrelevant for people who do not have this propensity. Or you may think that a particular crime prevention programme may work in some environments but not in others. The interest in this kind of conditional hypothesis is growing.</p>
<p>One of the assumptions of the regression model is that the relationship between the response variable and your predictors is additive. That is, if you have two predictors <code>x1</code> and <code>x2</code>, regression assumes that the effect of <code>x1</code> on <code>y</code> is the same at all levels of <code>x2</code>. If that is not the case, then you are then violating one of the assumptions of the regression. This is in fact one of the most important assumptions of regression, even if researchers often overlook it.</p>
<p>One way of extending our model to accommodate for interaction effects is to add additional terms to our model, a third predictor <code>x3</code>, where <code>x3</code> is simply the product of multiplying <code>x1</code> by <code>x2</code>. Notice we keep a term for each of the <strong>main effects</strong> (the original predictors) as well as a new term for the interaction effect. “Analysts should include all constitutive terms when specifying multiplicative interaction models except in very rare circumstances” (Brambor et al., 2006: 66).</p>
<p>A nice way of understanding interactions effects is to think of ‘interaction’ meaning ‘depends on’. So if you include an interaction between variables <code>x1</code> and <code>x2</code> in your model, you’re saying that the value of <code>x1</code> <em>depends on</em> the value of <code>x2</code>.</p>
<div id="activity-9-interaction-effects" class="section level3 hasAnchor" number="8.11.1">
<h3><span class="header-section-number">8.11.1</span> Activity 9: Interaction effects<a href="regression-analysis-a-refresher.html#activity-9-interaction-effects" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>How do we do this in R? One way is to use the following notation in the formula argument. Notice how we have added a third term <code>RD90:SOUTH_f</code>, which is asking R to test the conditional hypothesis that resource deprivation may have a different impact on homicide for southern and northern counties.</p>
<div class="sourceCode" id="cb433"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb433-1"><a href="regression-analysis-a-refresher.html#cb433-1" tabindex="-1"></a>fit_5 <span class="ot">&lt;-</span> <span class="fu">lm</span>(HR90 <span class="sc">~</span> RD90 <span class="sc">+</span> SOUTH_f <span class="sc">+</span> RD90<span class="sc">:</span>SOUTH_f , <span class="at">data=</span>ncovr)</span>
<span id="cb433-2"><a href="regression-analysis-a-refresher.html#cb433-2" tabindex="-1"></a><span class="co"># which is equivalent to: </span></span>
<span id="cb433-3"><a href="regression-analysis-a-refresher.html#cb433-3" tabindex="-1"></a><span class="co"># fit_5 &lt;- lm(HR90 ~ RD90 * SOUTH_f , data=ncovr)</span></span>
<span id="cb433-4"><a href="regression-analysis-a-refresher.html#cb433-4" tabindex="-1"></a><span class="fu">summary</span>(fit_5)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = HR90 ~ RD90 + SOUTH_f + RD90:SOUTH_f, data = ncovr)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -17.055  -2.998  -0.566   2.227  68.136 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     4.5477     0.1586  28.675   &lt;2e-16 ***
## RD90            2.5814     0.1963  13.148   &lt;2e-16 ***
## SOUTH_f1        3.2612     0.2247  14.515   &lt;2e-16 ***
## RD90:SOUTH_f1   0.5622     0.2377   2.365   0.0181 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.292 on 3081 degrees of freedom
## Multiple R-squared:  0.3658, Adjusted R-squared:  0.3652 
## F-statistic: 592.4 on 3 and 3081 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>You see here that essentially you have only two inputs (resource deprivation and south) but several regression coefficients. Gelman and Hill (2007) suggest reserving the term input for the variables encoding the information and to use the term predictor to refer to each of the terms in the model. So here we have two inputs and three predictors (one for SOUTH, another for resource deprivation, and a final one for the interaction effect).</p>
<p>In this case the test for the interaction effect is significant, which suggests there is such an interaction. Let’s visualise the results with the <code>effects</code> package:</p>
<div class="sourceCode" id="cb435"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb435-1"><a href="regression-analysis-a-refresher.html#cb435-1" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">allEffects</span>(fit_5), <span class="at">ask=</span><span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="crime_mapping_textbook_files/figure-html/unnamed-chunk-262-1.png" width="672" /></p>
<p>Notice that essentially what we are doing is running two regression lines and testing whether the slope is different for the two groups. The intercept is different, we know that Southern counties are more violent, but what we are testing here is whether the level of homicide goes up in a steeper fashion (and in the same direction) for one or the other group as the level of resource deprivation goes up. We see that’s the case here. The estimated lines are almost parallel, but the slope is a bit more steep in the Southern counties. In southern counties, resource deprivation seems to have more of an impact on homicide than in northern counties.</p>
<p>A word of warning, the moment you introduce an interaction effect the meaning of the coefficients for the other predictors changes (what is often referred as to the “main effects” as opposed to the interaction effect). You cannot retain the interpretation we introduced earlier. Now, for example, the coefficient for the <code>SOUTH</code> variable relates the marginal effect of this variable when <code>RD90</code> equals zero. The typical table of results helps you to understand whether the effects are significant but offers little of interest that will help you to meaningfully interpret what the effects are. For this, it’s better that you use some of the graphical displays we have covered.</p>
<p>Essentially what happens is that the regression coefficients that get printed are interpretable only for certain groups. So now:</p>
<ul>
<li><p>The intercept still represents the predicted score of homicide for southern counties and have a score of 0 in resource deprivation (as before).</p></li>
<li><p>The coefficient of <em>SOUTH_f1</em> can now be thought of as the difference between the predicted score of homicide rate for northern counties <em>that have a score of 0 in resource deprivation</em> and northern counties <em>that have a score of 0 in resource deprivation</em>.</p></li>
<li><p>The coefficient of <em>RD90</em> now becomes the comparison of mean homicide rate <em>for southern</em> counties who differ by one point in resource deprivation.</p></li>
<li><p>The coefficient for the interaction term represents the difference in the slope for <em>RD90</em> comparing southern and northern counties, the difference in the slope of the two lines that we visualised above.</p></li>
</ul>
<p>Models with interaction terms are too often misinterpreted. we strongly recommend you read this piece by <a href="https://files.nyu.edu/mrg217/public/pa_final.pdf">Brambor et al (2005)</a> to understand some of the issues involved. When discussing logistic regression we will return to this and will consider tricks to ease the interpretation.</p>
<p>Equally, <a href="http://www.jstatsoft.org/v08/i15/paper">John Fox (2003)</a> piece on the <code>effects</code> package goes into much more detail than we can here to explain the logic and some of the options that are available when producing plots to show interactions with this package.</p>
</div>
</div>
<div id="model-building-and-variable-selection" class="section level2 hasAnchor" number="8.12">
<h2><span class="header-section-number">8.12</span> Model building and variable selection<a href="regression-analysis-a-refresher.html#model-building-and-variable-selection" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>How do you construct a good model? This partly depends on your goal, although there are commonalities. You do want to start with theory as a way to select your predictors and when specifying the nature of the relationship to your response variable (e.g., additive, multiplicative). Gelman and Hill (2007) provide a series of general principles<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a>. we would like to emphasise at this stage two of them:</p>
<ul>
<li><p>Include all input variables that, for substantive reasons, might be expected to be important in predicting the outcome.</p></li>
<li><p>For inputs with large effects, consider including their interactions as well.</p></li>
</ul>
<p>It is often the case that for any model, the response variable is only related to a subset of the predictors. There are some scenarios where you may be interested in understanding what is the best subset of predictors. Imagine that you want to develop a risk assessment tool to be used by police officers that respond to a domestic violence incident, so that you could use this tool for forecasting the future risk of violence. There is a cost to adding too many predictors. A police officer’s time should not be wasted gathering information on predictors that are not associated with future risk. So you may want to identify the predictors that will help in this process.</p>
<p>Ideally, we would like to perform variable selection by trying out a lot of different models, each containing a different subset of the predictors. There are various statistics that help in making comparisons across models. Unfortunately, as the number of potentially relevant predictors increases the number of potential models to compare increases exponentially. So you need methods that help you in this process. There are a number of tools that you can use for <strong>variable selection</strong> but this goes beyond the aims of this introduction. If you are interested you may want to read <a href="http://link.springer.com/chapter/10.1007/978-1-4614-7138-7_6">this</a>.</p>
</div>
<div id="regression-assumptions" class="section level2 hasAnchor" number="8.13">
<h2><span class="header-section-number">8.13</span> Regression assumptions<a href="regression-analysis-a-refresher.html#regression-assumptions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Although so far we have discussed the practicalities of fitting and interpreting regression models, in practical applications you want to first check your model and proceed from there. There is not much point spending time interpreting your model until you know that the model reasonably fits your data.</p>
<p>In previous data analysis modules we covered assumptions made by various statistical tests. The regression model also makes assumptions of its own. In fact, there are so many that we could spend an entire class discussing them. Gelman and Hill (2007) point out that the most important regression assumptions by decreasing order of importance are:</p>
<ul>
<li><strong>Validity</strong>. The data should be appropriate for the question that you are trying to answer:</li>
</ul>
<blockquote>
<p>“Optimally, this means that the outcome measure should accurately reflect the phenomenon of interest, the model should include all relevant predictors, and the model should generalize to all cases to which it will be applied… Data used in empirical research rarely meet all (if any) of these criteria precisely. However, keeping these goals in mind can help you be precise about the types of questions you can and cannot answer reliably”</p>
</blockquote>
<ul>
<li><p><strong>Additiviy and linearity</strong>. These are the most important mathematical assumptions of the model. We already talked about additivity in the previous section and discussed how you can include interaction effects in your models if the additivity assumption is violated. We will discuss problems with non-linearities today as well as ways to diagnose and solve this problem. If the relationship is non linear (e.g, it is curvilinear) predicted values will be wrong in a biased manner, meaning that predicted values will systematically miss the true pattern of the mean of y (as related to the x-variables).</p></li>
<li><p><strong>Independence of errors</strong>. Regression assumes that the errors from the prediction line (or hyperplane) are independent. If there is dependency between the observations (you are assessing change across the same units, working with spatial units, or with units that are somehow grouped such as students from the same class), you may have to use models that are more appropriate (e.g., multilevel models, spatial regression, etc.).</p></li>
<li><p><strong>Equal variances of errors</strong>. When the variance of the residuals is unequal, you may need different estimation methods. This is, nonetheless, considered a minor issue. There is a small effect on the validity of t-test and F-test results, but generally regression inferences are robust with regard to the variance issue.</p></li>
<li><p><strong>Normality of errors</strong>. The residuals should be normally distributed. Gelman and Hill (2007: 46) discuss this as the least important of the assumptions and in fact “do <em>not</em> recommend diagnostics of the normality of the regression residuals”. If the errors do not have a normal distribution, it usually is not particularly serious. Regression inferences tend to be robust with respect to normality (or nonnormality of the errors). In practice, the residuals may appear to be nonnormal when the wrong regression equation has been used. So, we will show you how to inspect normality of the residuals not because this is a problem on itself, but because it may be give you further evidence that there is some other problem with the model you are applying to your data.</p></li>
</ul>
<p>Apart from this, it is convenient to diagnose multicollinearity (this affects interpretation) and influential observations.</p>
<p>So these are the assumptions of linear regression.</p>
<p>In this section we can go through very quickly how to test for some of them using visuals. While finding that some of the assumptions are violated do not necessarily mean that you have to scrap your model, it is important to use these diagnostics to illustrate that you have considered what the possible issues with your model is, and if you find any serious issues that you address them.</p>
<p>In r, we can use the <code>plot()</code> function on our output lm object to look through some diagnostics. This gives us 4 plots, so to show them all, we’ll use the code <code>par(mfrow = c(2, 2))</code> to split our plot window into 4 panes (remember to set back, run <code>par(mfrow = c(1, 1))</code>). For example, let’s return to <code>fit_1</code>, our very first model.</p>
<div class="sourceCode" id="cb436"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb436-1"><a href="regression-analysis-a-refresher.html#cb436-1" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb436-2"><a href="regression-analysis-a-refresher.html#cb436-2" tabindex="-1"></a><span class="fu">plot</span>(fit_1)</span></code></pre></div>
<p><img src="crime_mapping_textbook_files/figure-html/unnamed-chunk-263-1.png" width="672" /></p>
<p>The 4 plots we get are</p>
<ul>
<li><strong>Residuals vs Fitted</strong>. Used to check the linear relationship assumptions. A horizontal line, without distinct patterns is an indication for a linear relationship, what is good.</li>
<li><strong>Normal Q-Q</strong>. Used to examine whether the residuals are normally distributed. It’s good if residuals points follow the straight dashed line.</li>
<li><strong>Scale-Location (or Spread-Location)</strong>. Used to check the homogeneity of variance of the residuals (homoscedasticity). Horizontal line with equally spread points is a good indication of homoscedasticity. This is not the case in our example, where we have a bit of a heteroscedasticity problem (remember funnel-shape from the video!).</li>
<li><strong>Residuals vs Leverage</strong>. Used to identify influential cases, that is extreme values that might influence the regression results when included or excluded from the analysis.</li>
</ul>
<p>We can also run some tests to confirm what we see in the plots.</p>
<p>For example, to test for heteroskedasticity (unequal variance in our residuals) we can run a Breusch-Pagan test from the <code>lmtest</code> package or a NCV test from the <code>car</code> package.</p>
<div class="sourceCode" id="cb437"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb437-1"><a href="regression-analysis-a-refresher.html#cb437-1" tabindex="-1"></a>lmtest<span class="sc">::</span><span class="fu">bptest</span>(fit_1)  <span class="co"># Breusch-Pagan test</span></span></code></pre></div>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  fit_1
## BP = 75.912, df = 1, p-value &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb439"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb439-1"><a href="regression-analysis-a-refresher.html#cb439-1" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">ncvTest</span>(fit_1) <span class="co"># NCV test</span></span></code></pre></div>
<pre><code>## Non-constant Variance Score Test 
## Variance formula: ~ fitted.values 
## Chisquare = 598.5657, Df = 1, p = &lt; 2.22e-16</code></pre>
<p>Both these test have a p-value less that a significance level of 0.05, therefore we can reject the null hypothesis that the variance of the residuals is constant and infer that heteroscedasticity is indeed present, thereby confirming our graphical inference.</p>
<p>For testing whether the residuals violate the normality assumption, we can use the <code>ols_test_normality()</code> function from the <code>olsrr</code> package.</p>
<div class="sourceCode" id="cb441"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb441-1"><a href="regression-analysis-a-refresher.html#cb441-1" tabindex="-1"></a>olsrr<span class="sc">::</span><span class="fu">ols_test_normality</span>(fit_1)</span></code></pre></div>
<pre><code>## -----------------------------------------------
##        Test             Statistic       pvalue  
## -----------------------------------------------
## Shapiro-Wilk              0.8917         0.0000 
## Kolmogorov-Smirnov        0.078          0.0000 
## Cramer-von Mises         254.8478        0.0000 
## Anderson-Darling          46.495         0.0000 
## -----------------------------------------------</code></pre>
<p><strong>NOTE: </strong>You may have noticed the second of this assumption is independence of errors. This is an issue with spatial data. If you have spatial autocorrelation basically you are saying that your observations are not independent. What happens in area X is likely to be similar to what happens in its surrounding neighbours (if you have positive spatial autocorrelation). What do you do? Well, that’s what we will cover next week. We will learn how to fit regression models where you have spatial dependency.</p>
<p>Alright, that’s enough for this week!</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p><a href="http://link.springer.com/chapter/10.1007/978-1-4614-9170-5_15">This</a> is a fine chapter too if you struggle with the explanations in the required reading. Many universities, like the University of Manchester, have full access to Springer ebooks. You can also have a look at <a href="http://people.stern.nyu.edu/wgreene/Statistics/MultipleRegressionBasicsCollection.pdf">these notes</a>.<a href="regression-analysis-a-refresher.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p><a href="http://blog.minitab.com/blog/adventures-in-statistics/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit">This</a> is a reasonable explanation of how to interpret R-Squared.<a href="regression-analysis-a-refresher.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p><a href="http://www.sumsar.net/blog/2013/12/an-animation-of-the-construction-of-a-confidence-interval/">This blog post</a> provides a nice animation of the confidence interval and hypothesis testing.<a href="regression-analysis-a-refresher.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p><a href="http://vudlab.com/simpsons/">This</a> is a nice illustration of the Simpon’s Paradox, a well known example of omitted variable bias.<a href="regression-analysis-a-refresher.html#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>we recommend reading chapter 13 “Woes of regression coefficients” of an old book Mostseller and Tukey (1977) Data Analysis and Regression. Reading: Addison-Wesley Publishing.<a href="regression-analysis-a-refresher.html#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>Look at <a href="http://www.r-bloggers.com/stop-using-bivariate-correlations-for-variable-selection/">this</a> too.<a href="regression-analysis-a-refresher.html#fnref6" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="global-and-local-spatial-autocorrelation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="spatial-regression-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/08-week8.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["crime_mapping_textbook.pdf", "crime_mapping_textbook.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
